[{"content":"Hôm nay, trong một buổi chiều cuối thu ở Sài Gòn nhộn nhịp, có một chàng trai đang ngồi ôn lại kiến thức để chuẩn bị tham gia phỏng vấn trong căn nhà nhỏ. Bên ngoài cửa sổ, trời đang đổ những cơn mưa rào kèm những đợt sấm chớp lan man. Lòng ta lại suy tư về một thứ gì đó muốn được viết ra cho nhẹ nỗi lòng, thôi thì ta hãy cùng viết về SOLID nhé.\n1. Truyền thuyết về SOLID trong giang hồ Trong giang hồ lập trình, có một bộ tâm pháp được gọi là SOLID, truyền rằng ai lĩnh hội được thì code ắt tinh thông, hệ thống vững chãi, mở rộng vô biên. Bộ tâm pháp này gồm năm chiêu thức, mỗi chiêu đều ẩn chứa huyền cơ:\n1. Nhất Dụng Quy Tắc (Single Responsibility Principle) Mỗi cao thủ chỉ nên luyện một môn võ công, không nên tạp luyện đủ đường. Một class chỉ nên có một trách nhiệm, như kiếm khách chỉ dùng kiếm, không thể vừa múa kiếm vừa gõ trống. Giống như Kiều Phong chỉ cần một bộ Giáng Long Thập Bát Chưởng cũng đủ để xưng bá võ lâm khiến người người nể phục.\n2. Khai Bế Quy Tắc (Open/Closed Principle) Tâm pháp cần mở rộng để thêm chiêu thức mới, nhưng không được tùy tiện thay đổi căn cơ gốc rễ. Code cho phép mở rộng nhưng hạn chế sửa đổi, như môn phái có thể thu nhận thêm đệ tử nhưng tôn chỉ tổ sư thì bất biến.\n3. Thế Thân Quy Tắc (Liskov Substitution Principle) Đệ tử xuất sư, thay thế được sư phụ, hành tẩu giang hồ không làm loạn môn pháp. Class con thay thế class cha mà không phá hỏng chương trình, như người nối nghiệp vẫn giữ trọn đạo nghĩa tông môn.\n4. Giao Diện Phân Ly Quy Tắc (Interface Segregation Principle) Bí kíp không nên viết dài dòng, bắt đệ tử học cả ngàn chiêu không cần thiết. Interface nên gọn nhẹ, tách nhỏ, ai luyện cái gì thì chỉ học đúng cái đó, tránh việc phải học cả những chiêu không dùng đến.\n5. Nghịch Hướng Quy Tắc (Dependency Inversion Principle) Cao thủ chân chính không phụ thuộc vào vũ khí tầm thường, mà nắm được đạo lý võ học. Module cấp cao không phụ thuộc trực tiếp vào cấp thấp, cả hai đều dựa trên trừu tượng. Như tướng quân cầm quân không dựa vào loại giáo mác cụ thể, mà dựa vào binh pháp.\nThế là năm chiêu tâm pháp SOLID đã bày ra. Người trong võ lâm lập trình nếu ngộ được thì đường code sẽ như giang sơn vững chắc, dễ sửa đổi, dễ mở rộng, không sợ bug tà đạo quấy nhiễu.\nVà cho đến ngày nay, trải qua hàng trăm năm tuổi, bộ tâm pháp ấy vẫn còn lưu giữ được những giá trị bền vững. Dẫu thời thế đã đổi thay, cục diện Nam Đế Bắc Cái, Đông Tà Tây Độc đã khép lại, thì thời đại của những anh hùng bàn phím (lập trình viên) lại xuất hiện. Và ta sẽ tiếp tục nói về cách ứng dụng của SOLID trong lập trình.\n2. Chi tiết về SOLID SOLID là bộ 5 nguyên tắc thiết kế hướng đối tượng giúp code dễ bảo trì, mở rộng và giảm phụ thuộc lẫn nhau.\n2.1 Single Responsibility Principle (SRP) Ý nghĩa: Mỗi class/module chỉ nên có một lý do để thay đổi. Hiểu đơn giản: Một class chỉ làm một việc duy nhất. Ví dụ: InvoicePrinter chỉ in hóa đơn, còn tính toán hóa đơn thì để InvoiceCalculator. // ❌ Sai: Class làm quá nhiều việc class Invoice { calculateTotal() { /* logic tính toán */ } printInvoice() { /* logic in ấn */ } saveToDB() { /* logic lưu DB */ } } // ✅ Đúng: Tách ra từng trách nhiệm riêng class InvoiceCalculator { calculateTotal() { /* logic tính toán */ } } class InvoicePrinter { print(invoice: InvoiceCalculator) { /* logic in ấn */ } } class InvoiceRepository { save(invoice: InvoiceCalculator) { /* logic lưu DB */ } } 2.2 Open/Closed Principle (OCP) Ý nghĩa: Code nên mở rộng được nhưng hạn chế chỉnh sửa trực tiếp. Hiểu đơn giản: Khi có yêu cầu mới → thêm class/method thay vì sửa code cũ. Ví dụ: Thêm class mới để mở rộng tính năng thay vì chỉnh sửa class cũ. // ❌ Sai: Phải sửa code khi thêm shape mới class AreaCalculator { calculate(shape: any) { if (shape.type === \u0026#34;circle\u0026#34;) return Math.PI * shape.radius ** 2; if (shape.type === \u0026#34;square\u0026#34;) return shape.side ** 2; // thêm loại shape khác -\u0026gt; phải sửa class này } } // ✅ Đúng: Mở rộng bằng cách thêm class, không sửa code cũ interface Shape { area(): number; } class Circle implements Shape { constructor(public radius: number) {} area() { return Math.PI * this.radius ** 2; } } class Square implements Shape { constructor(public side: number) {} area() { return this.side ** 2; } } class AreaCalculator { calculate(shape: Shape) { return shape.area(); } } 2.3 Liskov Substitution Principle (LSP) Ý nghĩa: Class con có thể thay thế hoàn toàn cho class cha mà không làm hỏng chương trình. Hiểu đơn giản: Nếu dùng class con mà hệ thống vẫn chạy ổn định như class cha thì mới đúng. Ví dụ: Chim sẻ có thể bay nên kế thừa \u0026ldquo;chim biết bay\u0026rdquo;, trong khi chim cánh cụt chỉ nên kế thừa \u0026ldquo;chim\u0026rdquo; chứ không nên ép vào nhóm \u0026ldquo;chim bay\u0026rdquo;. // ❌ Sai: Penguin không bay được nhưng kế thừa Bird với fly() class Bird { fly() { console.log(\u0026#34;I can fly!\u0026#34;); } } class Penguin extends Bird { fly() { throw new Error(\u0026#34;Penguin can\u0026#39;t fly!\u0026#34;); } } // ✅ Đúng: Tách abstraction phù hợp interface Bird { eat(): void; } interface FlyingBird extends Bird { fly(): void; } class Sparrow implements FlyingBird { eat() { console.log(\u0026#34;Sparrow eating\u0026#34;); } fly() { console.log(\u0026#34;Sparrow flying\u0026#34;); } } class Penguin implements Bird { eat() { console.log(\u0026#34;Penguin eating\u0026#34;); } } 2.4 Interface Segregation Principle (ISP) Ý nghĩa: Interface không nên quá \u0026ldquo;béo\u0026rdquo;, class không nên bị buộc implement những thứ không dùng. Hiểu đơn giản: Chia nhỏ interface cho từng nhu cầu cụ thể. Ví dụ: Máy in chỉ cần implement IPrinter, không cần phải gánh thêm IScanner hay IFax. // ❌ Sai: Class buộc phải implement cả method không cần interface IMachine { print(): void; scan(): void; fax(): void; } class OldPrinter implements IMachine { print() { console.log(\u0026#34;Printing...\u0026#34;); } scan() { throw new Error(\u0026#34;Not supported\u0026#34;); } fax() { throw new Error(\u0026#34;Not supported\u0026#34;); } } // ✅ Đúng: Chia nhỏ interface interface IPrinter { print(): void; } interface IScanner { scan(): void; } interface IFax { fax(): void; } class SimplePrinter implements IPrinter { print() { console.log(\u0026#34;Printing...\u0026#34;); } } class MultiFunctionPrinter implements IPrinter, IScanner, IFax { print() { console.log(\u0026#34;Printing...\u0026#34;); } scan() { console.log(\u0026#34;Scanning...\u0026#34;); } fax() { console.log(\u0026#34;Faxing...\u0026#34;); } } 2.5 Dependency Inversion Principle (DIP) Ý nghĩa: Code nên phụ thuộc vào abstraction (interface) thay vì implementation (class cụ thể). Hiểu đơn giản: Module cấp cao không nên phụ thuộc trực tiếp module cấp thấp, cả hai nên phụ thuộc vào abstraction. Ví dụ: ReportService gọi IReportRepository thay vì fix cứng vào MySQLReportRepository. // ❌ Sai: Service phụ thuộc trực tiếp vào DB cụ thể class MySQLReportRepository { getReports() { return [\u0026#34;report from MySQL\u0026#34;]; } } class ReportService { constructor(private repo: MySQLReportRepository) {} showReports() { return this.repo.getReports(); } } // ✅ Đúng: Phụ thuộc abstraction (interface) interface ReportRepository { getReports(): string[]; } class MySQLReportRepository implements ReportRepository { getReports() { return [\u0026#34;report from MySQL\u0026#34;]; } } class MongoReportRepository implements ReportRepository { getReports() { return [\u0026#34;report from MongoDB\u0026#34;]; } } class ReportService { constructor(private repo: ReportRepository) {} showReports() { return this.repo.getReports(); } } // Sử dụng const service = new ReportService(new MongoReportRepository()); console.log(service.showReports()); 3. Những điều lưu ý để tránh hiểu sai về SOLID. Khi nhìn lại quy tắc SRP, có thể thấy trong NestJS (và nhiều framework khác), mỗi service (ví dụ: UserService, PostService) thường gom hết CRUD (create, read, update, delete) trong một class duy nhất. Nhìn qua có vẻ vi phạm SRP, nhưng thực tế:\nNestJS service bản chất là application service, gom logic xử lý request liên quan đến một entity/domain. Việc có createUser, updateUser, deleteUser, getUser trong cùng UserService vẫn được xem là một trách nhiệm - đó là quản lý User. Nếu tách nhỏ thành UserCreationService, UserDeletionService, UserQueryService thì số lượng file/service tăng rất nhiều, gây over-engineering cho dự án. SOLID là nguyên tắc, không phải luật cứng nhắc. Trong dự án thực tế, người ta trade-off để code dễ đọc, dễ maintain quan trọng hơn việc \u0026ldquo;theo đúng giáo trình\u0026rdquo;. Nói cách khác: không phải là không theo SOLID, mà là áp dụng nó ở mức thực dụng, tránh over-engineering.\nNgày đã tắt nắng, bài viết cũng dài. Đến đây, chúc cho vị đại hiệp đọc xong bí kíp có thể vận dụng thành thạo, tung hoành giang hồ lập trình, khiến người đời hân hoan nể phục. Cáo từ.\n","permalink":"https://thanhhv.github.io/posts/solid/","summary":"\u003cp\u003eHôm nay, trong một buổi chiều cuối thu ở Sài Gòn nhộn nhịp, có một chàng trai đang ngồi ôn lại kiến thức để chuẩn bị tham gia phỏng vấn trong căn nhà nhỏ. Bên ngoài cửa sổ, trời đang đổ những cơn mưa rào kèm những đợt sấm chớp lan man. Lòng ta lại suy tư về một thứ gì đó muốn được viết ra cho nhẹ nỗi lòng, thôi thì ta hãy cùng viết về \u003cstrong\u003eSOLID\u003c/strong\u003e nhé.\u003c/p\u003e","title":"Bộ nguyên tắc SOLID trong lập trình là gì? (Phiên bản kiếp hiệp)"},{"content":"Khi làm việc với database chắc hẳn chúng ta đã quen với các câu lệnh như SELECT, UPDATE, INSERT, DELETE,\u0026hellip;\nGiả sử khi chạy một câu lệnh INSERT INTO ... để thêm record vào DB thì bên trong cơ sở dữ liệu sẽ làm những gì để xử lý?\nTrong bài viết này, hãy cùng mình tìm hiểu đằng sau một câu lệnh SQL khi thực thi sẽ đi qua những bước gì nhé.\n1. Kiến trúc logic của PostgreSQL Hình dưới mô tả kiến trúc tổng quát của PostgreSQL (Một vài thứ hơi advanced nên bạn có thể tìm hiểu thêm tài liệu bên ngoài để hiểu nó là gì nhé):\nClient Process và Backend Process Đây là nơi câu lệnh SQL được gửi từ command-line hoặc từ các tool như DataGrip, pgAdmin,\u0026hellip; tới backend của PostgreSQL.\nBackend sẽ parse câu lệnh, phân tích plan, thực thi và trả kết quả.\nShared Memory Vùng nhớ dùng chung cho tất cả backend, gồm:\nWAL Buffer: đệm tạm cho log (Write-Ahead Log) trước khi flush ra WAL file. Shared Buffers: cache page dữ liệu (table, index) thay vì đọc/ghi trực tiếp từ disk. CLOG hay pg_xact(Commit Log) Buffers: lưu trạng thái commit/abort của transaction. Temp Buffers: cho bảng tạm và sort/hash tạm. Other Buffers: các cấu trúc khác (lock tables, proc array,…). 💡 PostgreSQL (và hầu hết DBMS) đều ghi vào bộ nhớ trước rồi mới đẩy xuống disk, với 2 mục tiêu:\nTăng tốc độ\nShared Buffers giữ page dữ liệu đang truy cập/thay đổi → thao tác trên RAM nhanh hơn rất nhiều so với disk.\nKhi có thay đổi (INSERT/UPDATE/DELETE), backend chỉ cần ghi vào Shared Buffers và WAL Buffer → trả kết quả cho client ngay.\nĐảm bảo an toàn dữ liệu (Durability)\nPostgreSQL tuân thủ nguyên tắc Write-Ahead Logging (WAL): luôn ghi thay đổi vào WAL Buffer → WAL Files trước khi commit.\nNếu server crash, dữ liệu chưa kịp flush xuống Data Files vẫn có thể phục hồi từ WAL.\nWriter và Checkpointer Writer (Background Writer): định kỳ flush dirty pages từ Shared Buffers ra Data Files. Checkpointer: tại checkpoint, toàn bộ dirty pages được flush để tạo \u0026ldquo;mốc nhất quán\u0026rdquo; giúp recovery nhanh hơn khi crash. WAL Writer và WAL Files WAL Writer: flush dữ liệu từ WAL Buffer xuống WAL Files trên disk. WAL là cơ chế đảm bảo durability: ghi log trước khi ghi dữ liệu thực sự. Autovacuum Launcher \u0026amp; Worker Autovacuum Launcher: giám sát hệ thống, khởi chạy Autovacuum Worker khi cần. Autovacuum Worker: dọn row \u0026ldquo;chết\u0026rdquo; (do MVCC), freeze transaction id, cập nhật statistics → tránh phình table và giữ query planner tối ưu. 👉 Hình dung đơn giản: Autovacuum Launcher giống như scheduler → canh khi nào cần thì bật job. Job chính là Autovacuum Worker.\nData Files Nơi lưu trữ dữ liệu thực tế: table, index, TOAST, FSM, VM.\nWriter/Checkpointer sẽ flush Shared Buffers xuống Data Files.\n2. Kiến trúc vật lý của PostgreSQL Nếu bạn chưa có cài đặt PostgreSQL thì có thể dùng Docker cho nhẹ nhàng.\nImage chính thức: https://hub.docker.com/_/postgres\n(Mình sẽ viết một bài riêng về lý do nên dùng Docker sau 👌)\nSau khi cài xong, ta thử truy cập vào thư mục data để xem PostgreSQL lưu gì trong đó:\ncd /var/lib/postgresql/data ls Cùng tìm hiểu từng thư mục/file nhé:\n1. base/ Chứa dữ liệu của từng database. Mỗi database = 1 folder (tên folder = OID của database). Trong mỗi folder database: Mỗi table / index = 1 file (tên file = relfilenode ID). Đây chính là nơi dữ liệu \u0026ldquo;thực sự\u0026rdquo; của các bảng nằm. Ví dụ:\nTạo database mới:\nCREATE DATABASE thanhhv_db; Xem OID của nó:\nSELECT oid, datname FROM pg_database WHERE datname = \u0026#39;thanhhv_db\u0026#39;; Ta sẽ thấy kết quả trả về OID = 32768.\nNếu bạn truy cập vào thư mục base/ sẽ thấy có thư mục 32768, chính là nơi PostgreSQL lưu dữ liệu của thanhhv_db.\nBạn có thể tạo thêm table trong database này để quan sát file phát sinh.\n2. global/ Chứa metadata toàn cụm (cluster-wide). Một số file quan trọng: pg_database → thông tin database pg_auth → user, role pg_control → thông tin khởi động cluster, checkpoint, timeline, version… 3. pg_wal/ Lưu Write-Ahead Log (WAL) - log mọi thay đổi. Khi transaction commit, dữ liệu được ghi vào WAL trước → nếu crash thì phục hồi từ đây. Cực kỳ quan trọng để đảm bảo durability. 4. pg_tblspc/ Mặc định PostgreSQL sẽ tạo database và table trong thư mục base/. Nếu bạn tạo tablespace, PostgreSQL sẽ lưu dữ liệu ở đường dẫn bạn chỉ định (ví dụ HDD), còn trong pg_tblspc/ chỉ giữ symlink trỏ tới đó. Đây là cách phổ biến để tối ưu chi phí: Data nóng → SSD Data cũ/ít truy cập → HDD Ví dụ:\nTạo tablespace:\nCREATE TABLESPACE product_space OWNER postgres LOCATION \u0026#39;/mnt/hdd/pg_tablespace_product\u0026#39;; Tạo database sử dụng tablespace:\nCREATE DATABASE product_db WITH OWNER = postgres TABLESPACE = product_space; Khi đó database sẽ nằm ở /mnt/hdd/pg_tablespace_product thay vì /base.\n5. Transaction-related pg_xact/ → trạng thái commit/abort của transaction pg_multixact/ → lock chia sẻ giữa nhiều transaction pg_subtrans/ → mapping subtransaction → top-level transaction 6. Một số file đặc biệt pg_hba.conf → cấu hình kết nối (host-based authentication) postgresql.conf → cấu hình server postmaster.pid → PID của tiến trình Postgres, để tránh start trùng PG_VERSION → version PostgreSQL hiện tại ⚠️ Lưu ý:\nVới file config (postgresql.conf, pg_hba.conf), chỉ chỉnh trực tiếp khi cần. Ưu tiên update qua SQL (ALTER SYSTEM SET ...; SELECT pg_reload_conf();) để có log/tracking. Một số file đặc biệt (vd: pg_hba.conf) bắt buộc phải sửa tay vì không chỉnh qua SQL được. 3. Inspect một câu lệnh INSERT dưới góc nhìn Backend Engineer Giả sử khi chạy một câu lệnh như sau:\nINSERT INTO test VALUES (1, \u0026#39;thanhhv\u0026#39;); Quy trình xử lý có thể tóm gọn thành 5 bước chính:\nClient gửi SQL → Backend process nhận và parse, tạo execution plan.\nGhi dữ liệu vào bộ nhớ (Shared Buffers): record được thêm vào page trong RAM, đánh dấu dirty. Nếu có index thì index cũng được update trong buffer. Lúc này commit chưa cần data file, chỉ cần WAL được flush là đủ\nSinh log (WAL): thay đổi được ghi vào WAL Buffer.\nCommit: WAL được flush xuống disk (pg_wal/) → đảm bảo dữ liệu bền vững. PostgreSQL trả kết quả OK cho client.\nGhi dữ liệu thật: sau commit, dữ liệu trong buffer sẽ được background writer/checkpointer ghi dần ra data files. Nếu server crash trước đó thì sẽ phục hồi dựa trên WAL.\nỞ đây mình giải thích theo hướng một backend engineer cần nắm nên đã bỏ qua một vài advanced section bên trong. Những bước này thường chỉ cần thiết cho ai làm rất sâu về database. Nếu bạn có bổ sung hoặc góc nhìn khác, hãy để lại góp ý ở phần bình luận nhé 🚀\nCám ơn mọi người đã đọc đến đây 🙌 Hẹn gặp lại trong những bài viết sắp tới.\nChúc mọi người sẽ gặt hái được nhiều thành tựu trong quá trình học và làm việc với database của mình!\n","permalink":"https://thanhhv.github.io/posts/postgresql-fundamental/","summary":"\u003cp\u003eKhi làm việc với database chắc hẳn chúng ta đã quen với các câu lệnh như \u003ccode\u003eSELECT\u003c/code\u003e, \u003ccode\u003eUPDATE\u003c/code\u003e, \u003ccode\u003eINSERT\u003c/code\u003e, \u003ccode\u003eDELETE\u003c/code\u003e,\u0026hellip;\u003cbr\u003e\nGiả sử khi chạy một câu lệnh \u003ccode\u003eINSERT INTO ...\u003c/code\u003e để thêm record vào DB thì bên trong cơ sở dữ liệu sẽ làm những gì để xử lý?\u003cbr\u003e\nTrong bài viết này, hãy cùng mình tìm hiểu đằng sau một câu lệnh SQL khi thực thi sẽ đi qua những bước gì nhé.\u003c/p\u003e","title":"PostgreSQL xử lý câu lệnh DML như thế nào?"},{"content":"Chắc hẳn bạn đã quá quen thuộc với việc làm việc trong các team theo các mô hình quản lý như Agile, đặc biệt là trong các công ty lớn. Vì vậy hôm nay mình sẽ chia sẻ cho các bạn cách có thể làm việc hiệu quả hơn khi muốn đóng góp nhiều hơn vào các buổi planning, muốn nhận được đánh giá tốt hơn từ team, hoặc khi các bạn làm cho startup nơi đòi hỏi nỗ lực cá nhân cao do thiếu hụt về resource.\nĐó chính là lập kế hoạch theo quy tắc SMART.\n1. SMART là gì? Khi đặt mục tiêu, nhiều người thường bị mơ hồ: muốn học nhiều hơn, làm việc tốt hơn, hay tiết kiệm nhiều hơn… nhưng không biết đo lường ra sao.\nSMART là một nguyên tắc giúp biến mục tiêu “mơ hồ” thành cụ thể, rõ ràng và khả thi. Nó là viết tắt của:\nS (Specific - Cụ thể) M (Measurable - Đo lường được) A (Achievable - Khả thi) R (Relevant - Liên quan) T (Time-bound - Có thời hạn) Chúng ta hãy cùng đi vào chi tiết từng yếu tố.\nSpecific (Cụ thể) Mục tiêu phải rõ ràng, dễ hiểu, không chung chung.\n❌ Sai: \u0026ldquo;Tôi muốn giỏi tiếng Anh.\u0026rdquo;\n✅ Đúng: \u0026ldquo;Tôi muốn cải thiện kỹ năng nói tiếng Anh để giao tiếp trong công việc\u0026rdquo;\n👉 Khi cụ thể, bạn sẽ biết chính xác mình phải làm gì mỗi ngày.\nMeasurable (Đo lường được) Mục tiêu cần có thước đo để biết mình đã đạt hay chưa.\n❌ Sai: \u0026ldquo;Tôi sẽ luyện nghe tiếng Anh thường xuyên.\u0026rdquo;\n✅ Đúng: \u0026ldquo;Tôi sẽ nghe podcast tiếng Anh ít nhất 20 phút mỗi ngày và ghi chú lại 5 từ mới.\u0026rdquo;\n👉 Con số (20 phút, 5 từ) chính là thước đo để bạn kiểm tra tiến độ.\nAchievable (Khả thi) Mục tiêu phải nằm trong khả năng thực hiện, không quá viển vông, phù hợp với thời gian và năng lực.\n❌ Sai: \u0026ldquo;Trong 1 tháng tôi sẽ nói tiếng Anh như người bản xứ.\u0026rdquo;\n✅ Đúng: \u0026ldquo;Trong 1 tháng tôi sẽ học 200 từ vựng mới và dùng chúng để viết 10 đoạn hội thoại ngắn.\u0026rdquo;\n👉 Thử thách bản thân, nhưng vẫn cần thực tế dựa trên nguồn lực.\nRelevant (Liên quan) Mục tiêu cần gắn với định hướng lớn trong công việc hoặc cuộc sống.\n❌ Sai: \u0026ldquo;Tôi sẽ học thêm tiếng Anh để… cho vui.\u0026rdquo;\n✅ Đúng: \u0026ldquo;Tôi sẽ luyện tiếng Anh để giao tiếp tốt hơn trong công việc của một engineer và chuẩn bị phỏng vấn vào các công ty quốc tế.\u0026rdquo;\n👉 Khi mục tiêu có ý nghĩa với sự nghiệp, bạn sẽ dễ kiên trì hơn.\nTime-bound (Có thời hạn) Deadline giúp bạn tránh trì hoãn.\n❌ Sai: \u0026ldquo;Tôi sẽ học tiếng Anh để lên fluent.\u0026rdquo;\n✅ Đúng: \u0026ldquo;Tôi sẽ hoàn thành trình độ Basic trong 3 tháng, đạt Intermediate sau 4 tháng tiếp theo, và hướng đến Fluent sau 8 tháng nữa.\u0026rdquo;\n👉 Có mốc thời gian rõ ràng sẽ giúp bạn có lộ trình cụ thể và biết mình đang ở đâu.\n2. Vận dụng SMART vào lập kế hoạch cho một feature cụ thể Nếu đã đọc qua đoạn trên thì chắc bạn cũng hiểu sơ qua về cách lập kế hoạch theo SMART rồi. Bây giờ mình sẽ áp dụng nó vào một feature cụ thể mà mình từng làm trong dự án.\nDĩ nhiên đây chỉ là một feature nhỏ và phổ biến, không hề liên quan đến bảo mật hay thông tin nhạy cảm của công ty cũ nên hoàn toàn phù hợp để chia sẻ. (Nếu anh em trong công ty có đọc được bài này thì hoan hỉ nhé =))\nTình huống:\nHôm ấy là thứ 5, team sắp bước vào buổi planning cho sprint tiếp theo. Nội dung chính của sprint này là triển khai một module mới gọi là virtual-tag để quản lý thông tin trong hệ thống. Đây là cách mình và team Backend đã lên plan.\nSpecific - Xây dựng hệ thống Virtual Tag Thiết kế cơ sở dữ liệu quan hệ để quản lý virtual tag và mối quan hệ gán tag cho resource. Xây dựng đầy đủ API CRUD cho việc tạo, đọc, cập nhật, xóa tag và thao tác gán/bỏ gán tag. Tích hợp với AWS, Azure, GCP để đồng bộ metadata của resource về hệ thống. Measurable - Tiêu chí đo lường Hoàn thành 95% các hạng mục:\nThiết kế Prisma schema và database modeling. Triển khai API endpoint cho toàn bộ thao tác liên quan đến tag. Mục tiêu hiệu năng:\n95% API response dưới 300ms. Achievable - Phương tiện thực hiện Triển khai bằng Node.js, NestJS, PostgreSQL và Prisma ORM. Tích hợp cloud qua AWS, GCP, Azure SDKs hoặc service module nội bộ. Sử dụng các service sẵn có để fetch dữ liệu resource từ cloud. Relevant - Tính liên quan Là chức năng cốt lõi của nền tảng FinOps. Cho phép gắn tag theo team, môi trường, cost center. Hỗ trợ tăng khả năng quan sát chi phí và tracking. Giúp giảm resource không được gắn tag và cải thiện governance. Time-bound - Thời hạn Triển khai: 72 giờ Sửa lỗi: 8 giờ Viết tài liệu: 6 giờ 👉 Tổng thời gian ước tính: 86 giờ ≈ 10,5 ngày làm việc\nTất nhiên, thực tế cần break nhỏ từng task để estimate chính xác hơn. Thường thì mình sẽ tạm chia trên Excel, sau đó đưa vào Jira và refine lại cùng team để có con số cuối cùng. Đôi khi những cuộc họp có thể khiến kế hoạch ban đầu bị xáo trộn, nhưng nhờ có sự chuẩn bị, chúng ta có thể nhanh chóng thích nghi và tái cấu trúc lại plan của bản thân cũng như của team để vẫn đạt được mục tiêu chung.\nVí dụ về break task\nVí dụ về 1 plan hoàn chỉnh\nKết luận Việc lập kế hoạch theo SMART giúp buổi planning trong sprint dễ dàng hơn, giúp mình nêu ra vấn đề, phân tích việc nào thực sự cần thiết và có tính khả thi với dự án. Nó mang lại rất nhiều giá trị, đặc biệt nếu bạn là một developer và muốn tiến xa hơn (senior, leader) thì đây là kỹ năng bắt buộc phải có.\nCon số và ví dụ trong bài mang tính tham khảo, mỗi dự án sẽ có điều chỉnh khác nhau, hy vọng nó sẽ mang lại 1 ít giá trị cho bạn. Thank you!\n","permalink":"https://thanhhv.github.io/posts/smart/","summary":"\u003cp\u003eChắc hẳn bạn đã quá quen thuộc với việc làm việc trong các team theo các mô hình quản lý như \u003cstrong\u003eAgile\u003c/strong\u003e, đặc biệt là trong các công ty lớn. Vì vậy hôm nay mình sẽ chia sẻ cho các bạn cách có thể làm việc hiệu quả hơn khi muốn đóng góp nhiều hơn vào các buổi planning, muốn nhận được đánh giá tốt hơn từ team, hoặc khi các bạn làm cho startup nơi đòi hỏi nỗ lực cá nhân cao do thiếu hụt về resource.\u003cbr\u003e\nĐó chính là \u003cstrong\u003elập kế hoạch theo quy tắc \u003ccode\u003eSMART\u003c/code\u003e\u003c/strong\u003e.\u003c/p\u003e","title":"Lập kế hoạch công việc hiệu quả với SMART"},{"content":"Khi làm việc với các hệ thống FinOps thì có 2 thứ quan trọng chúng ta cần phải quan tâm đó chính là perspective, thứ 2 là showback và chargeback. Trong bài viết này mình sẽ chia sẻ lại tại sao chúng quan trọng và làm sao để có thể dễ dàng quản lý chúng bằng module virtual tag trong các hệ thống FinOps.\nBắt đầu nào, dĩ nhiên là ngoài những cái này ra thì FinOps cũng có rất nhiều thứ quan trọng cần phải chú ý nhưng ở đây ta chỉ nói về những cái này thôi nhé.\n1. Cách thức hoạt động cơ bản của 1 hệ thống FinOps Một hệ thống FinOps về cơ bản sẽ gồm có các job hoặc pipeline để lấy dữ liệu từ cloud về (bao gồm: usage, billing, resource, metadata\u0026hellip;) thường dùng do các API của cloud cung cấp.\nSau đó sẽ:\nChuẩn hoá và lưu trữ nó vào CSDL (PostgreSQL, ClickHouse), Phân tích – tối ưu chi phí – báo cáo dựa trên dữ liệu đó. 2. Perspective là gì? Perspective dịch sang tiếng Việt là góc nhìn. Trong FinOps, nó là cách biểu diễn chi phí tài nguyên một cách trực quan, giúp quản trị viên nhìn ra:\nDòng tiền Chi phí Sự phân bổ tài nguyên Từ đó đưa ra các chiến lược tối ưu hoá.\nPerspective không phải là một resource cố định. Nó là cách biểu diễn dữ liệu phân tích, lọc theo logic. Ví dụ:\nDựa vào tag env=production trên AWS, bạn lọc tài nguyên có tag đó và thấy:\nTháng này: EC2, S3 production tiêu $2000 Tháng trước: chỉ $1000\n→ Từ đây bạn biết cần phân tích gì tiếp theo để tối ưu chi phí. 3. Showback và Chargeback là gì? Hãy tưởng tượng bạn đi ăn nhà hàng với team 5 người. Bạn gọi nhiều món, và hóa đơn như sau:\nCá chiên: 200k Cơm chiên: 200k Thịt gà: 300k Canh: 200k Tráng miệng: 200k Nước uống: 250k Tổng: 1.350k (không biết tính nhẩm có đúng không nữa =))) Bạn thanh toán trước, rồi chia tiền lại cho từng người trong team.\n➤ Quá trình nhà hàng đưa hoá đơn và bạn thanh toán gọi là Showback ➤ Quá trình bạn chia lại tiền cho từng người gọi là Chargeback Trong môi trường Cloud thì sao? Công ty bạn có nhiều team, dùng chung AWS cloud, mỗi team làm 1 dự án. Bạn là sếp, thấy bill tháng vừa rồi là $4000.\nCông ty trả tiền → Showback Bạn muốn xem chi tiết từng team xài bao nhiêu → gửi báo cáo để họ tối ưu tháng sau → Chargeback Lưu ý: Không bắt buộc mỗi team phải hoàn tiền, chỉ mang tính minh bạch và tối ưu hoá.\n4. Virtual tag là gì? Tại sao nó lại cần thiết? Virtual Tag trong FinOps là một cơ chế gắn nhãn logic (logical/derived tagging) cho dữ liệu chi phí cloud mà không cần tag thật trên resource.\nVì:\nKhông phải resource nào cũng được gắn tag Cùng 1 chức năng nhưng mỗi cloud tag khác nhau (VD: AWS prod, GCP production) → khó gom nhóm khi tạo perspective ➡️ Virtual Tag là nhãn \u0026ldquo;ảo\u0026rdquo; sinh ra từ dữ liệu, giúp phân bổ chi phí chính xác hơn, không phụ thuộc hoàn toàn vào tag gốc.\n🎯 Mục đích của Virtual Tag Tăng Cost Visibility: Gom nhóm tài nguyên theo team, project, env, service\u0026hellip; kể cả khi không có tag thật Khắc phục tagging sai/thiếu: Cho phép gắn logic thay thế Phân tích \u0026amp; báo cáo chi phí: Tạo perspective linh hoạt cho BI dashboard, Looker,\u0026hellip; Tóm lại:\nVirtual Tag → tạo nên Perspective → phục vụ cho Showback/Chargeback của hệ thống\n💡 Thiết kế cơ bản của hệ thống Virtual Tag Tạo bảng virtualTag để lưu thông tin tag Liên kết bảng resource thông qua bảng trung gian resourceTag Quan hệ n-n là hợp lý (1 resource có nhiều tag, 1 tag áp dụng cho nhiều resource) → Sau đó có thể dễ dàng đánh tag cho resource, tạo perspective và query theo tag trong bảng virtualTag.\nBonus: Tự động đánh tag bằng rule engine Khi đã có module virtual tag thì nên có thêm module rule engine - gọi là tag-rule-engine.\n📌 Lý do: Dữ liệu FinOps lấy từ cloud cực lớn (hàng chục triệu record) Thủ công đánh tag là không khả thi 🛠 Ví dụ rule: Nếu 1 resource trong tháng vừa rồi xài \u0026gt; $200 → tự động gán virtual tag là expensive\nCron job sẽ check điều kiện, nếu đúng → gán tag. Sau này cần lọc resource expensive thì rất nhanh. Dưới đây là 1 thiết kế cơ bản nhất của 1 rule tag-engine. Nó bao gồm 1 cái condition để dữ liệu có thể được match và 1 action để trigger hành động khi match với condition đó. Viết blog nên làm đơn giản vậy thôi, thực tế nó cũng vậy à, chỉ là có râu ria thêm tí thui =))\n✅ Lưu ý khi triển khai:\nLưu log các tag đã gán để tracking Ghi lại tác nhân gán tag: SYSTEM, USER,\u0026hellip; Hết rồi nếu có góp ý gì moi người nhận xét vào bên dưới giúp mình nha. Thank you.\n","permalink":"https://thanhhv.github.io/posts/virtual-tag-in-finops/","summary":"\u003cp\u003eKhi làm việc với các hệ thống FinOps thì có 2 thứ quan trọng chúng ta cần phải quan tâm đó chính là \u003cstrong\u003eperspective\u003c/strong\u003e, thứ 2 là \u003cstrong\u003eshowback và chargeback\u003c/strong\u003e. Trong bài viết này mình sẽ chia sẻ lại tại sao chúng quan trọng và làm sao để có thể dễ dàng quản lý chúng bằng module \u003cstrong\u003evirtual tag\u003c/strong\u003e trong các hệ thống FinOps.\u003c/p\u003e\n\u003cp\u003eBắt đầu nào, dĩ nhiên là ngoài những cái này ra thì FinOps cũng có rất nhiều thứ quan trọng cần phải chú ý nhưng ở đây ta chỉ nói về những cái này thôi nhé.\u003c/p\u003e","title":"Designing a virtual tag module in FinOps"},{"content":"\nThe architecture of Kubernetes is divided into two main parts:\n1. Control Plane Components The Control Plane is the brain of Kubernetes — responsible for managing the overall state of the cluster and orchestrating all activities.\n1.1 kube-apiserver Acts as the central communication gateway of the system. All requests from kubectl, the Dashboard, CI/CD pipelines, etc., are sent through this component. Responsible for: Authentication Authorization Reading/writing data from/to etcd Forwarding requests to other components Example:\nYou run kubectl get pods → the request goes to the kube-apiserver.\n1.2 etcd etcd is the key-value store used by Kubernetes to persist cluster state. It stores: Pod names, namespaces Replica counts ConfigMaps, Secrets, etc. If etcd loses data → the entire cluster can malfunction. It\u0026rsquo;s important to back it up regularly.\n1.3 kube-scheduler When a new Pod is created (but not yet assigned to a node), the scheduler will: Check the available resources across all nodes Evaluate constraints (affinity, taints, zones, etc.) Decide the best node to place the pod on Note: the scheduler only makes the placement decision — it doesn\u0026rsquo;t create the pod itself.\n1.4 kube-controller-manager Runs various built-in controllers to manage cluster state, such as: ReplicationController: ensures the correct number of pod replicas NodeController: monitors node status (up/down) JobController: handles one-time jobs ServiceAccountController, and more Example:\nIf you declare 3 pods and one crashes → the controller automatically recreates it.\nIt acts as a gatekeeper that ensures the actual cluster state matches the YAML you applied. 1.5 cloud-controller-manager (optional) Separates cloud provider logic from the Kubernetes core. Common functions: Creating external Load Balancers (e.g., GCP, AWS ELB) Automatically attaching cloud volumes (e.g., EBS, PersistentDisk) Updating node IPs in Services GKE, EKS, and AKS all utilize this component under the hood.\n2. Node Components Node components run on every node in the cluster (both master and worker nodes) to ensure:\nPods are running correctly Containers are managed properly Networking functions as expected 2.1 kubelet The main agent running on each node. It receives instructions from the kube-apiserver and performs actions such as: Creating pods Monitoring container health and status Reporting pod status back to the Control Plane Ensures that the actual state of the pod matches the desired state defined in YAML. If a pod crashes, the kubelet will attempt to restart it (if allowed by the restart policy).\n2.2 kube-proxy Manages networking rules using iptables or IPVS. Handles internal load balancing and forwards traffic to the appropriate pods. Ensures that: Pods can communicate with each other Pods can access external networks if required Example:\nWhen you access a ClusterIP service, kube-proxy routes the request to one of the underlying pods.\n2.3 Container Runtime The runtime engine responsible for running containers. It performs tasks such as: Pulling images (e.g., from Docker Hub, GCR) Creating containers from those images Managing container lifecycle (start, stop, restart) Common container runtimes:\nRuntime Notes containerd Default in Kubernetes 1.20+ (lightweight, fast) Docker Previously popular, now deprecated in recent K8s CRI-O Lightweight, designed specifically for Kubernetes ","permalink":"https://thanhhv.github.io/posts/kubernetes-components/","summary":"\u003cp\u003e\u003cimg alt=\"K8s component\" loading=\"lazy\" src=\"/posts/kubernetes-components/k8s-components.png\"\u003e\u003c/p\u003e\n\u003cp\u003eThe architecture of Kubernetes is divided into two main parts:\u003c/p\u003e\n\u003ch2 id=\"1-control-plane-components\"\u003e1. Control Plane Components\u003c/h2\u003e\n\u003cp\u003eThe Control Plane is the \u003cstrong\u003ebrain of Kubernetes\u003c/strong\u003e — responsible for managing the overall state of the cluster and orchestrating all activities.\u003c/p\u003e\n\u003ch3 id=\"11-kube-apiserver\"\u003e1.1 kube-apiserver\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eActs as the central communication gateway of the system.\u003c/li\u003e\n\u003cli\u003eAll requests from \u003ccode\u003ekubectl\u003c/code\u003e, the Dashboard, CI/CD pipelines, etc., are sent through this component.\u003c/li\u003e\n\u003cli\u003eResponsible for:\n\u003cul\u003e\n\u003cli\u003eAuthentication\u003c/li\u003e\n\u003cli\u003eAuthorization\u003c/li\u003e\n\u003cli\u003eReading/writing data from/to \u003ccode\u003eetcd\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eForwarding requests to other components\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003eExample:\u003cbr\u003e\nYou run \u003ccode\u003ekubectl get pods\u003c/code\u003e → the request goes to the kube-apiserver.\u003c/p\u003e","title":"Kubernetes Components"},{"content":"When learning Kubernetes, there are two core concepts you should understand: Kubernetes Object Model and Declarative Management. Let\u0026rsquo;s break down both of these.\n1. Kubernetes Object Model Everything in Kubernetes is an object, and these objects are managed via YAML or JSON definitions. They represent the resources in your system.\nCluster A cluster is a group of machines (nodes) consisting of:\nControl Plane (master) - responsible for managing the system. Worker Nodes - where your applications run. Node A node is a physical or virtual machine within a cluster.\nEach node includes:\nkubelet: manages pods on the node. container runtime: runs containers (e.g., Docker, containerd). kube-proxy: handles networking rules and traffic. Pod A pod is the smallest deployable unit in Kubernetes.\nIt contains one or more containers (usually one). All containers in a pod:\nShare the same IP address and volume. Are created and terminated together. Container A container is your running application (e.g., Node.js, Golang, Redis).\nIt is created from a container image and runs inside a pod.\nDeployment A deployment defines the desired state of your pods:\nHow many replicas? What image should be used? Should it auto-restart on failure? You simply define the desired state (e.g., \u0026ldquo;I want 3 pods running image my-app:v1\u0026rdquo;) and Kubernetes takes care of the rest.\nService A service exposes a set of pods via a stable endpoint.\nSince pods can change IP addresses, services help by:\nProviding load balancing. Enabling service discovery. Examples: ClusterIP, NodePort, LoadBalancer.\nConfigMap \u0026amp; Secret Used to inject configuration into containers:\nConfigMap: stores non-sensitive data (e.g., ENV variables, app name). Secret: stores sensitive data (e.g., passwords, API keys). Volume / PersistentVolume Used to store data outside the container, so it won\u0026rsquo;t be lost when the container restarts.\nVolumes can be mounted into pods.\nIngress Allows external traffic to access services inside the cluster.\nYou can define routes like /api or domains like app.domain.com.\nIngress is supported out of the box in GKE.\nNamespace Namespaces divide a cluster into multiple logical environments:\ndev, staging, production\u0026hellip; They help separate and organize resources effectively.\n2. Declarative Management In Kubernetes, you don\u0026rsquo;t run step-by-step commands (imperative).\nInstead, you declare your desired state using YAML.\nFor example:\n\u0026ldquo;I want 3 pods running image my-app:v1.0.0.\u0026rdquo;\nKubernetes will:\nCompare the current state with the desired state. Automatically make adjustments: create pods, restart if they fail, scale up/down as needed. You simply apply the file, and Kubernetes takes care of everything else.\nkubectl apply -f deployment.yaml ","permalink":"https://thanhhv.github.io/posts/kubernetes-concept/","summary":"\u003cp\u003eWhen learning Kubernetes, there are two core concepts you should understand: \u003cstrong\u003eKubernetes Object Model\u003c/strong\u003e and \u003cstrong\u003eDeclarative Management\u003c/strong\u003e. Let\u0026rsquo;s break down both of these.\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"K8s concept\" loading=\"lazy\" src=\"/posts/kubernetes-concept/k8s-concept.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"1-kubernetes-object-model\"\u003e1. Kubernetes Object Model\u003c/h2\u003e\n\u003cp\u003eEverything in Kubernetes is an \u003cstrong\u003eobject\u003c/strong\u003e, and these objects are managed via YAML or JSON definitions. They represent the resources in your system.\u003c/p\u003e\n\u003ch3 id=\"cluster\"\u003eCluster\u003c/h3\u003e\n\u003cp\u003eA \u003cstrong\u003ecluster\u003c/strong\u003e is a group of machines (nodes) consisting of:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eControl Plane (master)\u003c/strong\u003e - responsible for managing the system.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWorker Nodes\u003c/strong\u003e - where your applications run.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"node\"\u003eNode\u003c/h3\u003e\n\u003cp\u003eA \u003cstrong\u003enode\u003c/strong\u003e is a physical or virtual machine within a cluster.\u003cbr\u003e\nEach node includes:\u003c/p\u003e","title":"Kubernetes Concepts"},{"content":"\nIn Google Cloud, Billing is the system that helps you manage costs, payments, and budgets when using services on Google Cloud Platform (GCP), such as Compute Engine, BigQuery, Cloud Storage, and more. Below are the four most important components in Google Cloud Billing:\n1. Budget Allows you to set a spending limit for a specific time period (e.g., month, quarter) for a project or billing account. Purpose: Avoid spending beyond your planned budget. Example: You\u0026rsquo;re building a backend for a crawling system running on GCP, using multiple VMs or Cloud Functions. To control cost, you set a $500/month budget to track your expenses. 2. Alert Alerts are automatically triggered when spending exceeds a defined percentage of the budget (e.g., 50%, 90%, 100%). Purpose: Notify you when costs spike unexpectedly — possibly due to a bug or misconfiguration. Example: If the cost of your backend on Cloud Run reaches 90% of the $500 budget, you’ll receive an email notification to take action. 3. Report A visual tool to analyze GCP spending over time, across services (e.g., Compute, BigQuery), projects, or by using labels. Purpose: Understand where your costs come from → optimize resource usage. Example: A report shows BigQuery is consuming 60% of your backend budget. You decide to add Redis caching to reduce query load → lower costs. 4. Quotes (Cost Estimation) Use the Google Cloud Pricing Calculator to estimate costs before deploying your system. Purpose: Plan finances in advance and report estimated spending to your manager or PM — avoid surprises when receiving the actual bill. Example: Before launching a backend with Cloud Run + Firestore, you use the calculator to estimate a cost of $200/month, based on expected request volume and traffic. ","permalink":"https://thanhhv.github.io/posts/google-cloud-billing/","summary":"\u003cp\u003e\u003cimg alt=\"gg-billing\" loading=\"lazy\" src=\"/posts/google-cloud-billing/gg-billing.png\"\u003e\u003c/p\u003e\n\u003cp\u003eIn Google Cloud, \u003cstrong\u003eBilling\u003c/strong\u003e is the system that helps you manage \u003cstrong\u003ecosts, payments, and budgets\u003c/strong\u003e when using services on Google Cloud Platform (GCP), such as Compute Engine, BigQuery, Cloud Storage, and more. Below are the four most important components in Google Cloud Billing:\u003c/p\u003e\n\u003ch2 id=\"1-budget\"\u003e1. Budget\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eAllows you to set a \u003cstrong\u003espending limit\u003c/strong\u003e for a specific time period (e.g., month, quarter) for a project or billing account.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePurpose:\u003c/strong\u003e Avoid spending beyond your planned budget.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExample:\u003c/strong\u003e You\u0026rsquo;re building a backend for a crawling system running on GCP, using multiple VMs or Cloud Functions. To control cost, you set a \u003cstrong\u003e$500/month\u003c/strong\u003e budget to track your expenses.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"2-alert\"\u003e2. Alert\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eAlerts are \u003cstrong\u003eautomatically triggered\u003c/strong\u003e when spending exceeds a defined percentage of the budget (e.g., 50%, 90%, 100%).\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePurpose:\u003c/strong\u003e Notify you when costs spike unexpectedly — possibly due to a bug or misconfiguration.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExample:\u003c/strong\u003e If the cost of your backend on Cloud Run reaches \u003cstrong\u003e90% of the $500 budget\u003c/strong\u003e, you’ll receive an email notification to take action.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"budget-alert\" loading=\"lazy\" src=\"/posts/google-cloud-billing/budget-alert.png\"\u003e\u003c/p\u003e","title":"Google Cloud Billing"},{"content":"In Google Cloud, Compute Offering is a set of services that help you run workloads (like applications, APIs, batch jobs, etc.) on Google\u0026rsquo;s host infrastructure. Depending on your workload and requirements, you can choose from the options below:\n1. Compute Engine (IaaS - Infrastructure as a Service) A virtual machine where you have full permission to configure the environment. High level of control, similar to traditional hosting on the cloud. Use case: Configure OS in detail, install custom software, need full system control. Example: Run a Node.js/Golang server, cron job, or backend AI model training. AWS equivalent: EC2 2. App Engine (PaaS - Platform as a Service) A platform for running applications where you only need to deploy code — Google handles everything else (scaling, patching, infrastructure, etc.). Low level of control — just push your code, no need to manage servers. Use case: Rapid development, no infrastructure management needed. Example: Run a small API server, REST API, or MVP web app. AWS equivalent: Elastic Beanstalk 3. Cloud Run (Serverless Containers) Run containers (e.g., Docker) in a serverless model. Billing is based on request duration. Medium level of control — you manage the container image, while Google handles scaling and infrastructure. Use case: Leverage the benefits of containers + serverless for lightweight backends or microservices. Example: Run an API service, webhook receiver, or AI inference container. AWS equivalent: App Runner / Fargate 4. Google Kubernetes Engine (GKE) (CaaS - Container as a Service) Run containerized applications with Kubernetes. Google manages the control plane. High level of control — you can fully configure your cluster, while Google manages some parts of it. Use case: Need orchestration, CI/CD pipelines, or complex multi-service applications. Example: Run a microservices system, CI job runners, or real-time data pipelines. AWS equivalent: EKS 5. Cloud Functions (FaaS - Function as a Service) Write and deploy small functions that are triggered by events (HTTP, Pub/Sub, Cloud Storage, etc.). Extremely easy to use — just write a function, no need to manage infrastructure. Use case: Handle small event-driven logic, time-based triggers, or system integration tasks. Example: Auto-resize images, handle webhooks from Telegram/Stripe, send emails on user registration. AWS equivalent: Lambda ","permalink":"https://thanhhv.github.io/posts/google-cloud-compute-offering/","summary":"\u003cp\u003eIn Google Cloud, \u003cstrong\u003eCompute Offering\u003c/strong\u003e is a set of services that help you run workloads (like applications, APIs, batch jobs, etc.) on Google\u0026rsquo;s host infrastructure. Depending on your workload and requirements, you can choose from the options below:\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"gg-cloud-comute-offering\" loading=\"lazy\" src=\"/posts/google-cloud-compute-offering/gg-compute-offering.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"1-compute-engine-iaas---infrastructure-as-a-service\"\u003e1. Compute Engine (IaaS - Infrastructure as a Service)\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eA virtual machine where you have full permission to configure the environment.\u003c/li\u003e\n\u003cli\u003eHigh level of control, similar to traditional hosting on the cloud.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eUse case:\u003c/strong\u003e Configure OS in detail, install custom software, need full system control.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExample:\u003c/strong\u003e Run a Node.js/Golang server, cron job, or backend AI model training.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAWS equivalent:\u003c/strong\u003e EC2\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"2-app-engine-paas---platform-as-a-service\"\u003e2. App Engine (PaaS - Platform as a Service)\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eA platform for running applications where you only need to deploy code — Google handles everything else (scaling, patching, infrastructure, etc.).\u003c/li\u003e\n\u003cli\u003eLow level of control — just push your code, no need to manage servers.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eUse case:\u003c/strong\u003e Rapid development, no infrastructure management needed.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExample:\u003c/strong\u003e Run a small API server, REST API, or MVP web app.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAWS equivalent:\u003c/strong\u003e Elastic Beanstalk\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"3-cloud-run-serverless-containers\"\u003e3. Cloud Run (Serverless Containers)\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eRun containers (e.g., Docker) in a serverless model. Billing is based on request duration.\u003c/li\u003e\n\u003cli\u003eMedium level of control — you manage the container image, while Google handles scaling and infrastructure.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eUse case:\u003c/strong\u003e Leverage the benefits of containers + serverless for lightweight backends or microservices.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExample:\u003c/strong\u003e Run an API service, webhook receiver, or AI inference container.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAWS equivalent:\u003c/strong\u003e App Runner / Fargate\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"4-google-kubernetes-engine-gke-caas---container-as-a-service\"\u003e4. Google Kubernetes Engine (GKE) (CaaS - Container as a Service)\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eRun containerized applications with Kubernetes. Google manages the control plane.\u003c/li\u003e\n\u003cli\u003eHigh level of control — you can fully configure your cluster, while Google manages some parts of it.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eUse case:\u003c/strong\u003e Need orchestration, CI/CD pipelines, or complex multi-service applications.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExample:\u003c/strong\u003e Run a microservices system, CI job runners, or real-time data pipelines.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAWS equivalent:\u003c/strong\u003e EKS\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"5-cloud-functions-faas---function-as-a-service\"\u003e5. Cloud Functions (FaaS - Function as a Service)\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eWrite and deploy small functions that are triggered by events (HTTP, Pub/Sub, Cloud Storage, etc.).\u003c/li\u003e\n\u003cli\u003eExtremely easy to use — just write a function, no need to manage infrastructure.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eUse case:\u003c/strong\u003e Handle small event-driven logic, time-based triggers, or system integration tasks.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExample:\u003c/strong\u003e Auto-resize images, handle webhooks from Telegram/Stripe, send emails on user registration.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAWS equivalent:\u003c/strong\u003e Lambda\u003c/li\u003e\n\u003c/ul\u003e","title":"Google Cloud Compute Offering"},{"content":"Chào mọi người, hôm nay trong lúc mình ôn tập kiến thức thì nhớ đến Bloom Filter, thế là mình lại phải viết thêm một bài nói về cái này nữa rồi =))\nBloom Filter là một cấu trúc dữ liệu xác suất được thiết kế để kiểm tra nhanh chóng xem một phần tử có thuộc tập hợp hay không.\nCông dụng của nó là kiểm tra nhanh xem \u0026ldquo;Cái này có chưa nhỉ?\u0026rdquo;\nNếu nó bảo là chưa có → chắc chắn là chưa. Nếu nó bảo là có rồi → có thể có, hoặc là nhầm :D Ví dụ về cách hoạt động của Bloom Filter Khởi tạo một mảng bit (0,0,0,0,\u0026hellip;). Khởi tạo một vài hàm băm (h1, h2, h3,\u0026hellip;). Khi thêm một phần tử, dùng các hàm băm để tính ra các vị trí trong mảng bit → set các vị trí đó thành 1. Khi kiểm tra phần tử khác, băm ra các vị trí tương ứng và kiểm tra xem các bit đó đã là 1 chưa. Minh họa ví dụ Giả sử bài toán là: Nhận một đoạn text, nếu đoạn text đã tồn tại thì báo lỗi, nếu chưa thì thêm vào.\n1. Khởi tạo mảng bit Giả sử 8 bit: [0,0,0,0,0,0,0,0] (Chọn 8 cho dễ minh họa, thực tế có thể hàng ngàn bit. Nếu quá nhỏ → dễ xung đột bit, tăng false positive. Nếu quá lớn → tốn bộ nhớ.)\n2. Định nghĩa hàm băm: h1(x) = (sum of ASCII letters) % 8 h2(x) = (length of string * 3) % 8 3. Thêm phần tử cat h1(\u0026ldquo;cat\u0026rdquo;) = (99 + 97 + 116) % 8 = 312 % 8 = 0 → bit[0] = 1 h2(\u0026ldquo;cat\u0026rdquo;) = 3 * 3 = 9 → 9 % 8 = 1 → bit[1] = 1 Mảng bit: [1,1,0,0,0,0,0,0]\n4. Kiểm tra phần tử dog h1(\u0026ldquo;dog\u0026rdquo;) = (100 + 111 + 103) = 314 → 314 % 8 = 2 h2(\u0026ldquo;dog\u0026rdquo;) = 3 * 3 = 9 → 9 % 8 = 1 Kiểm tra bit[2] = 0 → chắc chắn dog chưa có → set bit[2] = 1\nMảng bit: [1,1,1,0,0,0,0,0]\n5. Thêm phần tử duck h1(\u0026ldquo;duck\u0026rdquo;) = (100 + 117 + 99 + 107) = 423 % 8 = 7 h2(\u0026ldquo;duck\u0026rdquo;) = 4 * 3 = 12 → 12 % 8 = 4 Update: bit[7] = 1, bit[4] = 1\nMảng bit: [1,1,1,0,1,0,0,1]\n6. Kiểm tra lại cat h1(\u0026ldquo;cat\u0026rdquo;) = 0, h2(\u0026ldquo;cat\u0026rdquo;) = 1 → bit[0] và bit[1] đều = 1 → có thể tồn tại → cần kiểm tra lại DB để chắc chắn. 7. Ví dụ dương tính giả với god h1(\u0026ldquo;god\u0026rdquo;) = (103 + 111 + 100) = 314 % 8 = 2 h2(\u0026ldquo;god\u0026rdquo;) = 3 * 3 = 9 % 8 = 1 bit[2] = 1, bit[1] = 1 → Bloom Filter nói: \u0026ldquo;god có thể tồn tại\u0026rdquo;. Nhưng thực tế chưa từng thêm god. → Đây là false positive: các phần tử trước đó đã vô tình bật bit đó.\nCác trường hợp sử dụng phổ biến trong backend ✅ Kiểm tra nhanh username đã tồn tại chưa Người dùng nhập username = gavin\nHash gavin bằng h1, h2 → bật các bit tương ứng → lưu mảng bit vào Redis\nLần sau có người nhập gavin, hash lại:\nNếu ít nhất 1 bit = 0 → chắc chắn chưa tồn tại → cho phép tạo tài khoản Nếu tất cả bit = 1 → có thể đã tồn tại → cần truy vấn DB để xác thực ➡️ Giảm tải cho DB, phản hồi nhanh\n⚠️ Bloom Filter không thay thế DB, vì có thể false positive\n✅ Kiểm tra blacklist, spam IP/email Dùng Bloom Filter để lưu các IP/email bị chặn Trước khi xử lý request, check nhanh qua Bloom Filter ➡️ Rất nhanh và nhẹ, tiết kiệm truy vấn\nHy vọng bài viết giúp bạn hiểu rõ hơn về Bloom Filter và ứng dụng nó vào các hệ thống thực tế một cách hiệu quả!\n","permalink":"https://thanhhv.github.io/posts/bloom-filter/","summary":"\u003cp\u003eChào mọi người, hôm nay trong lúc mình ôn tập kiến thức thì nhớ đến Bloom Filter, thế là mình lại phải viết thêm một bài nói về cái này nữa rồi =))\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eBloom Filter\u003c/strong\u003e là một cấu trúc dữ liệu xác suất được thiết kế để kiểm tra nhanh chóng xem một phần tử có thuộc tập hợp hay không.\u003c/p\u003e\n\u003cp\u003eCông dụng của nó là kiểm tra nhanh xem \u003cem\u003e\u0026ldquo;Cái này có chưa nhỉ?\u0026rdquo;\u003c/em\u003e\u003c/p\u003e","title":"Bloom filter là gì và trường hợp sử dụng"},{"content":"Hợp đồng thông minh DEX Trong một sàn giao dịch phi tập trung (DEX) như Uniswap, nhiều hợp đồng thông minh làm việc cùng nhau để cho phép hoán đổi token. Các hợp đồng chính thường bao gồm: Factory, Router, và Pair. Vai trò của từng hợp đồng như sau:\n🔹 1. Factory Contract Là nơi đăng ký chính của các pool thanh khoản (cặp token). Tạo ra pool thanh khoản mới khi có thêm cặp giao dịch mới. Lưu trữ ánh xạ giữa các cặp token và địa chỉ của hợp đồng Pair tương ứng. Các hàm chính:\ncreatePair(tokenA, tokenB): Triển khai hợp đồng Pair mới cho cặp tokenA và tokenB. getPair(tokenA, tokenB): Trả về địa chỉ hợp đồng Pair. allPairs(): Trả về danh sách tất cả các cặp đã tạo. Ví dụ:\nNếu người dùng muốn giao dịch Token A ↔ Token B mà chưa có pool, Factory sẽ tạo hợp đồng Pair mới.\n🔹 2. Router Contract Là hợp đồng chính mà người dùng tương tác để hoán đổi token, thêm/bớt thanh khoản và định tuyến giao dịch. Gọi đến Factory để tìm hợp đồng Pair tương ứng. Đảm bảo giá tốt nhất bằng cách định tuyến giao dịch qua nhiều cặp token. Các hàm chính:\nswapExactTokensForTokens(amountIn, minAmountOut, path, recipient, deadline): Hoán đổi amountIn của Token A sang Token B. addLiquidity(tokenA, tokenB, amountA, amountB, minA, minB, to, deadline): Thêm thanh khoản vào một Pair. removeLiquidity(tokenA, tokenB, liquidity, minA, minB, to, deadline): Rút thanh khoản khỏi Pair. Ví dụ:\nNgười dùng muốn đổi Token A sang Token B:\nRouter kiểm tra tuyến giao dịch tối ưu (trực tiếp hoặc qua nhiều cặp). Gọi đến hợp đồng Pair để thực hiện giao dịch. Token được chuyển giao tương ứng. 🔹 3. Pair Contract (Liquidity Pool) Quản lý pool thanh khoản cho một cặp token. Sử dụng công thức AMM sản phẩm không đổi:\nx * y = k\nTrong đó x và y là lượng token dự trữ, k là hằng số không đổi. Các hàm chính:\nswap(amount0Out, amount1Out, to): Thực hiện hoán đổi token. mint(to): Mint token LP (liquidity provider). burn(to): Burn token LP và trả lại token gốc. getReserves(): Trả về lượng token dự trữ. Ví dụ:\nNếu có giao dịch Token A → Token B:\nNgười dùng gửi Token A vào hợp đồng Pair. Pair tính toán số Token B trả lại dựa vào công thức AMM. Gửi Token B cho người dùng, cập nhật dự trữ. 🛠 Các hợp đồng khác trong DEX 🔹 4. Multicall Contract (tùy chọn) Cho phép thực hiện nhiều lệnh gọi hợp đồng trong một giao dịch (ví dụ: kiểm tra nhiều giá cùng lúc). 🔹 5. Fee Collection Contract (tùy chọn) Nếu DEX thu phí giao thức, sẽ có hợp đồng riêng để thu và phân phối phí. 🎯 Cách các hợp đồng phối hợp với nhau Tạo cặp token mới:\nFactory triển khai hợp đồng Pair nếu chưa tồn tại. Thêm thanh khoản:\nNgười dùng gọi Router, Router nạp token vào Pair contract. Người dùng nhận lại token LP. Hoán đổi token:\nNgười dùng gọi Router để hoán đổi. Router tìm đúng Pair và thực hiện swap. Rút thanh khoản:\nNgười dùng trả lại token LP cho Router, Router rút tài sản từ Pair. 🚀 Ví dụ luồng swap Giả sử bạn muốn hoán đổi 100 USDT → ETH trên DEX:\nNgười dùng gọi:\nswapExactTokensForTokens(100 USDT, minETH, [USDT, ETH], recipient, deadline) Router truy xuất hợp đồng Pair (USDT/ETH) từ Factory. Pair tính toán số ETH trả lại theo công thức AMM. Gửi ETH cho người dùng, USDT thêm vào dự trữ. 🔥 Tổng kết Hợp đồng Mục đích Factory Tạo và theo dõi các hợp đồng Pair (pool thanh khoản). Router Xử lý swap, định tuyến, quản lý thanh khoản. Pair Giữ token dự trữ, thực hiện swap theo AMM. Multicall (tuỳ chọn) Gộp nhiều lệnh gọi hợp đồng thành một giao dịch. Fee Collection (tuỳ chọn) Thu và phân phối phí giao thức. Uniswap V2 - Công thức sản phẩm không đổi và cách tính giá Uniswap V2 hoạt động theo mô hình AMM (Automated Market Maker), nơi tính thanh khoản trong pool được duy trì bởi công thức sản phẩm không đổi:\nx * y = k\nTrong đó:\nx = Số lượng Token X trong pool y = Số lượng Token Y trong pool k = Hằng số không đổi sau mỗi giao dịch Ví dụ:\nToken X là ETH Token Y là USDT Thiết lập ban đầu Pool có:\n1000 ETH 500,000 USDT k = 1000 * 500,000 = 500,000,000\nBước 1: Tính giá ban đầu Giá ETH theo USDT:\n1 ETH = 500 USDT\nBước 2: Giao dịch swap Người dùng swap 100 ETH → USDT\nETH trong pool: 1000 → 1100\nUSDT giảm để giữ k = 500,000,000\nBước 3: Tính USDT mới 1100 * y' = 500,000,000 → y' = 454,545.45 USDT\nBước 4: Tính số USDT nhận được 500,000 - 454,545.45 = 45,454.55 USDT\nBước 5: Giá ETH mới 1 ETH ≈ 412.37 USDT\nTóm tắt Trạng thái ETH USDT Giá ETH Trước swap 1000 500,000 500 USDT Sau swap 1100 454,545.45 412.37 USDT Kết luận Tác động giá: Giá ETH giảm vì tỉ lệ thay đổi. Sản phẩm không đổi: k không đổi, đảm bảo thanh khoản. Lợi ích LP: Kiếm phí nhưng có nguy cơ tổn thất tạm thời. Bài viết được mình dịch từ duyquoc1508, cám ơn Quốc vì đã có 1 bài viết quá chi tiết này.\n","permalink":"https://thanhhv.github.io/posts/dex/","summary":"\u003ch2 id=\"hợp-đồng-thông-minh-dex\"\u003eHợp đồng thông minh DEX\u003c/h2\u003e\n\u003cp\u003eTrong một sàn giao dịch phi tập trung (DEX) như Uniswap, nhiều hợp đồng thông minh làm việc cùng nhau để cho phép hoán đổi token. Các hợp đồng chính thường bao gồm: \u003cstrong\u003eFactory\u003c/strong\u003e, \u003cstrong\u003eRouter\u003c/strong\u003e, và \u003cstrong\u003ePair\u003c/strong\u003e. Vai trò của từng hợp đồng như sau:\u003c/p\u003e\n\u003ch3 id=\"-1-factory-contract\"\u003e🔹 1. Factory Contract\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eLà nơi đăng ký chính của các pool thanh khoản (cặp token).\u003c/li\u003e\n\u003cli\u003eTạo ra pool thanh khoản mới khi có thêm cặp giao dịch mới.\u003c/li\u003e\n\u003cli\u003eLưu trữ ánh xạ giữa các cặp token và địa chỉ của hợp đồng Pair tương ứng.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eCác hàm chính:\u003c/strong\u003e\u003c/p\u003e","title":"Tổng quan về Hợp đồng Thông minh trong DEX và AMM"},{"content":"Xin chào mọi người,\nTrong quá trình làm việc ở vị trí Backend Engineer, mình đã trải qua nhiều ngôn ngữ lập trình, trong đó có Node.js và Golang. Vậy trường hợp nào nên dùng Node.js, trường hợp nào nên dùng Golang? Bài viết này chia sẻ kinh nghiệm thực chiến cá nhân và quan sát thực tế từ đồng nghiệp xung quanh. Let\u0026rsquo;s start!\n1. Hiệu năng và Đa luồng Golang có hiệu năng tốt hơn nhờ là compiled language và mô hình goroutine rất nhẹ (lightweight thread do Go runtime quản lý), dễ dàng xử lý hàng nghìn concurrent connections mà tốn rất ít tài nguyên.\nNode.js dùng event loop, rất hiệu quả cho ứng dụng I/O-bound, nhưng dễ bị nghẽn khi xử lý CPU-bound do chạy đơn luồng (có thể dùng worker threads nhưng không phải là mặc định).\nVậy nên, nếu hệ thống cần xử lý song song, real-time, high concurrency → Golang là lựa chọn tốt.\nMình sẽ chú thích thêm 1 xíu về I/O-bound và CPU-bound là gì cho mọi người dễ follow nhé:\nI/O-bound: là tác vụ mà CPU phải chờ dữ liệu từ ngoài: đọc file, query DB, gởi request network\u0026hellip;\nawait fetch(\u0026#39;https://api.example.com/data\u0026#39;) CPU-bound: là tác vụ sử dụng nhiều CPU, như tính toán, mã hoá, AI\u0026hellip;\nfor (let i = 0; i \u0026lt; 1e9; i++) { // Tính toán số nguyên tố } 2. Tốc độ phát triển \u0026amp; Hệ sinh thái Node.js: ecosystem mạnh, npm phong phú, build nhanh, nhất là khi làm với frontend (JS/TS). Golang: code rõ ràng, nhưng viết nhiều hơn vì ít thư viện có sẵn. Nên nếu cần tốc độ phát triển nhanh → Nodejs là lựa chọn tốt.\n3. Maintainability \u0026amp; Readability Golang: strict typing, clear structure → dễ maintain trong team. Node.js: Typescript thì ổn, JavaScript thuần thì dễ sinh bug. Nên dự án quy mô lớn → Golang tốt hơn về dài hạn.\n4. Use Case thực tế Dự án DEX:\nGolang cho core server xử lý thuật toán tìm đường đi tối ưu nhất giữa các pool để swap token (CPU-bound). Node.js cho crawler/router (I/O-bound). Dự án web/blog:\nNode.js phù hợp do chủ yếu fetch dữ liệu DB trả về. 5. Khả năng xử lý I/O Thực ra Golang cũng xử lý I/O bất đồng bộ rất tốn nhờ goroutines và non-blocking calls. Nhưng có lý do tại sao người ta vẫn nói Nodejs mạnh hơn về I/O, đặc biệt là trong các hệ thống I/O intensive (API gateway, proxy server)\nYếu tố Node.js Golang I/O Handling Event loop + libuv + Non-blocking I/O Goroutine + epoll/kqueue (runtime quản lý) Concurrency Model Single-threaded với event loop Multi-threaded với goroutines Resource Usage Ít RAM (1 thread chính + thread pool khi cần) Nhẹ (goroutines ~2KB stack size) I/O Performance Cực nhanh cho I/O nhỏ Tốt nhưng có overhead khi nhiều goroutines Throughput Rất cao với lượng request nhỏ, nhanh Ổn định với request lớn, dài hạn Nodejs có event-loop hoạt động mạnh như disptacher trung tâm: Request nhỏ (đọc file, query db, network) được đưa và libuv. Không cần tạo thread mới -\u0026gt; do là single thread , chỉ cần 1 thread chính để quản lý mọi thứ. callback-based -\u0026gt; event loop chỉ cần biết là khi nào I/O xong để tiếp tục xử lý. Kết quả: với lượng I/O nhỏ và nhanh, nodejs cực kì nhanh và không bị lãng phí tài nguyên so với việc tạo goroutines/thread không cần thiết. Go thì khác: mỗi request sẽ tạo 1 goroutine (nhẹ, những vẫn là context riêng) Runtime của go quản lý goroutines bằng M:N Scheduler (map nhiều goroutines vào ít thread) Nếu request nhiều quá, runtime phải liên tục schedule và switch context -\u0026gt; có overhead dù nhỏ. Kết quả: với lượng I/O nhỏ, liên tục, việc context swiching quá nhiều có thể làm giảm hiệu suất so với nodejs. Khi nào Node.js vượt trội? API gateway (hàng triệu request/ngày) Chat app, notification Proxy server Streaming app (WebSocket, video chunks) ✅ I/O-heavy → Node.js\n✅ CPU-heavy → Golang\nNói chung cả Nodejs và Golang đều rất mạnh mẽ, nhưng chúng phù hợp với từng usecase khác nhau. Chúng ta nên quan trọng việc chọn đúng công cụ cho bài toán hơn là chỉ chọn theo sở thích cá nhân.\nCảm ơn bạn đã đọc đến đây. Hẹn gặp lại trong bài viết tiếp theo nhé! 🙌\n","permalink":"https://thanhhv.github.io/posts/nodejs-vs-go/","summary":"\u003cp\u003eXin chào mọi người,\u003c/p\u003e\n\u003cp\u003eTrong quá trình làm việc ở vị trí Backend Engineer, mình đã trải qua nhiều ngôn ngữ lập trình, trong đó có \u003cstrong\u003eNode.js\u003c/strong\u003e và \u003cstrong\u003eGolang\u003c/strong\u003e. Vậy trường hợp nào nên dùng Node.js, trường hợp nào nên dùng Golang? Bài viết này chia sẻ kinh nghiệm thực chiến cá nhân và quan sát thực tế từ đồng nghiệp xung quanh. Let\u0026rsquo;s start!\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"Nodejs-vs-Golang\" loading=\"lazy\" src=\"/posts/nodejs-vs-go/nodejs-go.png\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"1-hiệu-năng-và-đa-luồng\"\u003e1. Hiệu năng và Đa luồng\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eGolang\u003c/strong\u003e có hiệu năng tốt hơn nhờ là compiled language và mô hình \u003cstrong\u003egoroutine\u003c/strong\u003e rất nhẹ (lightweight thread do Go runtime quản lý), dễ dàng xử lý hàng nghìn concurrent connections mà tốn rất ít tài nguyên.\u003c/p\u003e","title":"So sánh Node.js và Golang trong Backend"},{"content":"Hôm nay, trong một buổi đầu tuần sau chuyến đi du lịch giữa năm, tôi tranh thủ ôn lại kiến thức để chuẩn bị cho buổi phỏng vấn vị trí Backend Blockchain sắp tới. Nhân tiện, tôi viết lại bài này để ghi nhớ kỹ thuật xác thực người dùng không cần tài khoản và mật khẩu, mà sử dụng đăng nhập bằng ví Web3 (như Metamask, Coin98 Super Wallet, Trust Wallet,\u0026hellip;). Cùng bắt đầu nhé! Quá trình này gồm 3 bước đơn giản:\n1. Lấy message từ server Đầu tiên, client sẽ gửi request đến server để lấy message về. Đây là nội dung mà client sẽ ký bằng ví như Metamask để xác thực với dApp.\nVì message cần được thống nhất giữa server và client, nên server nên là bên tạo và quản lý message này.\nVí dụ message: thanhhv.github.io wants you to sign in with your Ethereum account: 0xA1B2...D3E4 Sign-in request for MyDApp URI: https://thanhhv.github.io Version: 1 Chain ID: 1 Nonce: 839174 Issued At: 2025-05-11T20:40:00Z Đây là định dạng theo EIP-4361 (Sign-In With Ethereum) được sử dụng phổ biến.\nNonce là số ngẫu nhiên dùng một lần (có thể dùng UUID), kết hợp với timestamp để tránh replay attack.\nServer nên tạo nonce, lưu vào database với các field:\nnonce, wallet, expiresAt, used = false, sau đó gắn vào message trả về cho client.\n2. Client ký message bằng private key Sau khi nhận được message, client sẽ dùng private key để ký.\nVí dụ sử dụng thư viện ethers:\nconst { ethers } = require(\u0026#34;ethers\u0026#34;); const wallet = new ethers.Wallet(process.env.PRIVATE_KEY); const signature = await wallet.signMessage(message); Client sau đó gửi { message, signature } về server.\n3. Server xác thực chữ ký Server sẽ:\nTách nonce từ message ra. Truy vấn DB để kiểm tra: Có tồn tại không? Hết hạn chưa? Đã được sử dụng chưa? Sau đó, dùng ethers để xác thực chữ ký:\nconst { ethers } = require(\u0026#34;ethers\u0026#34;); const recoveredAddress = ethers.utils.verifyMessage(message, signature); const isValid = recoveredAddress.toLowerCase() === addressFromRequest; Nếu hợp lệ, server có thể cập nhật DB: used = true, và cho phép đăng nhập thành công.\n4. Bonus: Kết hợp với JWT Giả sử bạn đang xây dựng trang quản trị admin, sau khi bước 3 hoàn tất, server có thể tạo 1 JWT token. Những request tiếp theo sẽ dùng token này để xác thực — giống như mô hình web2 quen thuộc.\nTuy là đăng nhập bằng ví crypto, nhưng sau đó bạn có thể tương tác với hệ thống như người dùng thông thường, vừa an toàn, vừa tiện lợi.\nHết rồi! Hy vọng bài viết hữu ích cho bạn nào đang tìm hiểu về Web3 authentication. Chúc cho tôi sẽ may mắn vượt qua vòng phỏng vấn sắp tới nhé, hihi 😄\n","permalink":"https://thanhhv.github.io/posts/verify-user-wallet/","summary":"\u003cp\u003eHôm nay, trong một buổi đầu tuần sau chuyến đi du lịch giữa năm, tôi tranh thủ ôn lại kiến thức để chuẩn bị cho buổi phỏng vấn vị trí Backend Blockchain sắp tới. Nhân tiện, tôi viết lại bài này để ghi nhớ kỹ thuật xác thực người dùng không cần tài khoản và mật khẩu, mà sử dụng đăng nhập bằng ví Web3 (như Metamask, Coin98 Super Wallet, Trust Wallet,\u0026hellip;). Cùng bắt đầu nhé! Quá trình này gồm \u003cstrong\u003e3 bước đơn giản\u003c/strong\u003e:\u003c/p\u003e","title":"Xác thực người dùng bằng ví crypto"},{"content":"1. Cơ bản về cách blockchain thêm block Các blockchain như Ethereum, Bitcoin hoạt động như sau:\nMỗi node trong mạng sẽ giữ một bản sao của blockchain hiện tại. Khi một miner (hoặc validator) tìm được block mới hợp lệ, nó sẽ broadcast block đó cho mạng. Các node nhận block mới sẽ xác minh, nếu hợp lệ thì thêm vào chain của mình. Vấn đề xảy ra khi nhiều miner có thể tìm được block mới gần như cùng một lúc.\nGiả sử mạng lưới đang dừng ở block thứ 99. Miner A tìm ra block 100A và broadcast nó. Ở một nơi khác, Miner B cũng tìm ra một block 100B và broadcast. Do độ trễ mạng, các node khác nhau có thể nhận và thêm vào chuỗi khác nhau: 100A hoặc 100B.\nLúc này, blockchain tạo ra hai nhánh tạm thời (gọi là temporary fork) ở block thứ 100.\n2. Khi nào xảy ra re-org? Giả sử Miner C đào tiếp block 101 dựa trên 100B, chuỗi lúc này là:\nBlock 99 -\u0026gt; Block 100B -\u0026gt; Block 101 Trong khi đó, bạn đang theo chuỗi:\nBlock 99 -\u0026gt; Block 100A Theo quy tắc longest chain, blockchain sẽ chọn chuỗi dài hơn là chuỗi chính thức.\nVì vậy, chain 100B -\u0026gt; 101 sẽ được chấp nhận, và block 100A bị loại bỏ.\nQuá trình này gọi là chain reorganization (re-org).\nRe-org là lúc mà mạng đổi ý và chọn một nhánh mới dài hơn, bỏ qua nhánh cũ — giống như chơi cờ mà bỗng dưng đi lại nước trước đó vì thấy đường khác ngon hơn!\n3. Các kỹ thuật xử lý khi re-org xảy ra ở phía backend 3.1. Delay block confirmation Đây là cách phổ biến và đơn giản nhất.\nKhi indexing dữ liệu từ blockchain, bạn bỏ qua một vài block cuối cùng để tránh sai sót do re-org.\nVí dụ:\nTrên Ethereum, thường bỏ qua 12 block cuối (tức chỉ xử lý đến latest - 12). Các chain khác sẽ có con số riêng, bạn cần tra thêm tài liệu. Tuy nhiên, cách này có độ trễ nên có thể kèm theo giải pháp UI như:\n\u0026ldquo;Đang xử lý dữ liệu\u0026hellip; lần cập nhật gần nhất 1 phút trước\u0026rdquo;\n3.2. Xây dựng hệ thống rollback tự động (phức tạp hơn) Để dữ liệu gần như realtime nhưng vẫn chính xác, bạn có thể xây hệ thống hỗ trợ rollback khi re-org:\nKhi lưu dữ liệu từ block, luôn lưu kèm blockNumber và blockHash. Mỗi khi có block mới, kiểm tra lại N block trước đó (ví dụ: 12 block). Nếu blockHash không khớp với dữ liệu đã lưu: Rollback: xóa dữ liệu liên quan block cũ, sync lại block mới. Hoặc tạo record mới với trạng thái như: confirmed, reorged, replaced,\u0026hellip; để phục vụ audit. Phương pháp này chính xác hơn, nhưng phức tạp và tốn công hơn rất nhiều.\nViệc lựa chọn cách xử lý phù hợp nên linh hoạt tùy vào yêu cầu hệ thống và đặc thù sản phẩm bạn đang làm.\n👋 Kết Hy vọng bài viết giúp bạn hiểu rõ hơn về khái niệm re-org và cách đối phó với nó trong backend.\nCảm ơn mọi người đã đọc tới đây. Hẹn gặp lại ở bài viết tiếp theo nhé! 🚀\n","permalink":"https://thanhhv.github.io/posts/reorg-in-blockchain/","summary":"\u003ch2 id=\"1-cơ-bản-về-cách-blockchain-thêm-block\"\u003e1. Cơ bản về cách blockchain thêm block\u003c/h2\u003e\n\u003cp\u003eCác blockchain như Ethereum, Bitcoin hoạt động như sau:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMỗi node trong mạng sẽ giữ một bản sao của blockchain hiện tại.\u003c/li\u003e\n\u003cli\u003eKhi một miner (hoặc validator) tìm được block mới hợp lệ, nó sẽ broadcast block đó cho mạng.\u003c/li\u003e\n\u003cli\u003eCác node nhận block mới sẽ xác minh, nếu hợp lệ thì thêm vào chain của mình.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eVấn đề xảy ra khi nhiều miner có thể tìm được block mới gần như cùng một lúc.\u003cbr\u003e\nGiả sử mạng lưới đang dừng ở block thứ \u003ccode\u003e99\u003c/code\u003e. Miner A tìm ra block \u003ccode\u003e100A\u003c/code\u003e và broadcast nó. Ở một nơi khác, Miner B cũng tìm ra một block \u003ccode\u003e100B\u003c/code\u003e và broadcast. Do độ trễ mạng, các node khác nhau có thể nhận và thêm vào chuỗi khác nhau: 100A hoặc 100B.\u003c/p\u003e","title":"Re-org là gì? Backend Developer cần xử lý thế nào khi Blockchain \"đổi ý\""},{"content":"Xin chào các bạn,\nTrong bài viết này, tôi sẽ chia sẻ một số kinh nghiệm cá nhân khi phải lựa chọn giữa hai loại cơ sở dữ liệu phổ biến là SQL và NoSQL, cụ thể là PostgreSQL và MongoDB. Bài viết không đi sâu vào lý thuyết SQL hay NoSQL là gì, mà sẽ tập trung vào góc nhìn thực tế khi phải đưa ra lựa chọn trong một dự án cụ thể.\nTôi có thể khẳng định ngay từ đầu rằng không có loại cơ sở dữ liệu nào là \u0026ldquo;tốt nhất\u0026rdquo;, mà chỉ có loại phù hợp nhất với bối cảnh và yêu cầu của dự án tại thời điểm đó.\n1. Tính linh hoạt và yêu cầu thay đổi Nếu dự án có deadline gấp, trong khi yêu cầu nghiệp vụ hoặc schema dữ liệu còn mơ hồ và dễ thay đổi liên tục, tôi sẽ ưu tiên sử dụng NoSQL, cụ thể là MongoDB.\nLý do là vì MongoDB không yêu cầu schema cố định, cho phép thay đổi cấu trúc dữ liệu linh hoạt mà không cần thực hiện các bước migration phức tạp như với cơ sở dữ liệu quan hệ. Điều này giúp tiết kiệm đáng kể thời gian và công sức trong giai đoạn phát triển ban đầu.\n2. Tính ổn định, toàn vẹn dữ liệu và nghiệp vụ phức tạp Ngược lại, nếu dự án đòi hỏi tính toàn vẹn dữ liệu cao, chẳng hạn như các hệ thống tài chính, ngân hàng hoặc thương mại điện tử, thì tôi sẽ ưu tiên sử dụng SQL, như PostgreSQL.\nPostgreSQL hỗ trợ ACID tốt, xử lý tốt các mối quan hệ phức tạp, kể cả khi sử dụng dữ liệu JSON, mà vẫn đảm bảo hiệu năng. Cấu trúc dữ liệu rõ ràng, chặt chẽ giúp dễ dàng phát hiện và ngăn chặn lỗi logic từ sớm.\nNgược lại, MongoDB lại quá linh hoạt, điều này tiềm ẩn nhiều rủi ro nếu dev không kiểm soát tốt. Tôi từng gặp trường hợp trong một dự án mà nhiều team cùng sử dụng chung một MongoDB instance. Mỗi team lại định nghĩa collection Users theo cách riêng, với các field khác nhau — dẫn đến việc khó bảo trì, khó hiểu dữ liệu, và dễ phát sinh lỗi khó debug.\n3. Nguồn lực và năng lực của team Bên cạnh yêu cầu kỹ thuật, chúng ta cũng cần xem xét năng lực của team backend và team DevOps trong việc triển khai và vận hành hệ thống.\nNếu team đã quen sử dụng PostgreSQL hoặc có kinh nghiệm xử lý dữ liệu phức tạp, thì PostgreSQL sẽ là lựa chọn hiệu quả hơn. Nếu team mạnh về Node.js, JavaScript, và đã quen dùng Mongoose, thì có thể cân nhắc sử dụng MongoDB nếu phù hợp với yêu cầu dự án. Trong trường hợp nguồn lực hạn chế, chưa thể đầu tư cho một loại database mới, thì có thể tạm thời sử dụng giải pháp hiện tại, nhưng cần có kế hoạch cho việc chuyển đổi sau này, ví dụ như áp dụng Repository Pattern để tách biệt phần logic truy cập cơ sở dữ liệu khỏi business logic. 4. Tổng kết Tôi thường không chọn database theo cảm tính hay thói quen, mà sẽ đánh giá dựa trên các tiêu chí:\nYêu cầu nghiệp vụ Tính chất dữ liệu Deadline triển khai Năng lực đội ngũ kỹ thuật Tôi không tin vào “công nghệ tốt nhất”, mà tin vào “công nghệ phù hợp nhất với bài toán cụ thể tại thời điểm cụ thể”.\n","permalink":"https://thanhhv.github.io/posts/mongodb-vs-postgresql/","summary":"\u003cp\u003eXin chào các bạn,\u003c/p\u003e\n\u003cp\u003eTrong bài viết này, tôi sẽ chia sẻ một số kinh nghiệm cá nhân khi phải lựa chọn giữa hai loại cơ sở dữ liệu phổ biến là \u003cstrong\u003eSQL\u003c/strong\u003e và \u003cstrong\u003eNoSQL\u003c/strong\u003e, cụ thể là \u003cstrong\u003ePostgreSQL\u003c/strong\u003e và \u003cstrong\u003eMongoDB\u003c/strong\u003e. Bài viết không đi sâu vào lý thuyết SQL hay NoSQL là gì, mà sẽ tập trung vào góc nhìn thực tế khi phải đưa ra lựa chọn trong một dự án cụ thể.\u003c/p\u003e","title":"SQL vs NoSQL"},{"content":"🚀 This is the beginning of my Hugo + PaperMod powered blog hosted at thanhhv.github.io. Stay tuned for more!\n","permalink":"https://thanhhv.github.io/posts/welcome/","summary":"\u003cp\u003e🚀 This is the beginning of my Hugo + PaperMod powered blog hosted at \u003cstrong\u003ethanhhv.github.io\u003c/strong\u003e. Stay tuned for more!\u003c/p\u003e","title":"Welcome"},{"content":"👨‍💻 Hoang Van Thanh - Software Engineer 📍 Thu Duc, Ho Chi Minh City, Vietnam 📧 Email: thanhhv317@gmail.com 🐙 GitHub: @thanhhv 🔗 LinkedIn: linkedin.com/in/thanhhv317 📅 DOB: 11/08/1998 🛠 Skills Languages \u0026amp; Frameworks: Node.js (NestJS, Express), Go, TypeScript, JavaScript, REST API, GraphQL, gRPC Architecture: Microservices, Message Queue, Clean Architecture, WebSocket Databases: PostgreSQL, MongoDB, Meilisearch, Redis Blockchain: Web3.js, ethers, On-chain Data DevOps \u0026amp; Tools: Docker, AWS (EC2, S3, Lambda, SQS), Linux, GitHub Actions (CI/CD) Testing \u0026amp; Monitoring: Jest, Prometheus, Grafana, Jaeger, Tracing Frontend: React.js, HTML, CSS, Bootstrap Methodologies: Agile/Scrum Soft Skills: Problem solving, Teamwork \u0026amp; Collaboration, Planning \u0026amp; Task Management Languages: English 💼 Experience Cloudverse (05/2025 - 08/2025) — Senior Backend Engineer (Contractor) Project: Cloud Provider — Management platform for partner list using FinOps system\nDesigned and implemented Virtual Tag and Dynamic Perspective modules Optimized and developed APIs for frontend integration Maintained and upgraded system from Node.js v16 → v22 Conducted code reviews and trained new team members Tech: NestJS, GraphQL, PostgreSQL, Microservices Coin98 (09/2023 - 04/2025) — Backend Engineer Project: AmberBlocks — Blockchain CMS platform for Web3 content\nDesigned databases for tags, courses, series, etc. Integrated Meilisearch for full-text search Built business logic services with NestJS \u0026amp; GraphQL Developed shared libraries, wrote unit tests, refactored legacy code Tech: NestJS, GraphQL, PostgreSQL, Redis, gRPC, RabbitMQ, Meilisearch, InfluxDB, Docker, AWS (S3), SendGrid Project: OneID \u0026amp; KYC — Web3-based identity verification solution\nDesigned and optimized databases for performance Integrated smart contracts (Web3.js), tracked on-chain data Implemented KYC/KYB services and blockchain-based payment (VIC \u0026amp; BNB) Built modules for activity logging and secure authentication Tech: Node.js, MongoDB, Redis, Web3.js, WebSocket, SendGrid Project: Superwallet Market Service — Crypto portfolio \u0026amp; analytics\nMigrated JS → TS, refactored legacy services Crawled crypto data (CoinGecko, Debank APIs), built analytics Improved DB design for scalability \u0026amp; performance Tech: Express, MongoDB, Redis, Web3.js, AWS (S3, SQS, Lambda) Finviet Technology Corporation (10/2020 - 09/2023) — Backend Engineer Project: Loyalty — Scalable loyalty program system\nDesigned scalable databases \u0026amp; microservices Optimized MongoDB queries for high-volume transactions Integrated monitoring with Prometheus, Grafana, Jaeger Tech: Node.js, NestJS, MongoDB, ActiveMQ, Redis, ReactJS, Docker Project: Eco Consumer App — E-wallet, payments \u0026amp; loyalty\nDeveloped microservices with NestJS \u0026amp; WebSocket Integrated Eco e-wallet \u0026amp; third-party platforms Built schedulers for automated data exports Tech: Node.js, WebSocket, MongoDB, Redis, ActiveMQ, Firebase Project: Eco CMS Service — Backend for content \u0026amp; services\nRefactored legacy code, improved system performance Integrated Prometheus \u0026amp; Grafana for monitoring Built reports and dashboards for business data Tech: Node.js, TypeScript, MongoDB, Redis Eplus Solution \u0026amp; Technology (05/2019 - 09/2020) — Internship → Fresher Developer Developed backend with Go \u0026amp; Node.js Contributed to DB analysis and user management modules Extracted HTML from PDFs per designer’s requirements Implemented frontend features and integrated with backend Wrote unit tests and participated in Agile processes 🎓 Education Ho Chi Minh University of Education (2016 - 2020)\nFaculty of Information Technology\n🎯 About Me Software Engineer with 5+ years of experience designing and building scalable backend systems, specializing in Node.js, distributed services, and blockchain applications. Passionate about system design, microservices, and cloud-based platforms.\n📂 Projects \u0026amp; Links Blog: thanhhv.github.io GitHub: thanhhv 🎮 Hobbies Reading books, traveling, playing games\nLast updated: 2025-09-09\n","permalink":"https://thanhhv.github.io/cv/","summary":"\u003ch2 id=\"-hoang-van-thanh---software-engineer\"\u003e👨‍💻 Hoang Van Thanh - Software Engineer\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e📍 Thu Duc, Ho Chi Minh City, Vietnam\u003c/li\u003e\n\u003cli\u003e📧 Email: \u003ca href=\"mailto:thanhhv317@gmail.com\"\u003ethanhhv317@gmail.com\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e🐙 GitHub: \u003ca href=\"https://github.com/thanhhv\"\u003e@thanhhv\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e🔗 LinkedIn: \u003ca href=\"https://www.linkedin.com/in/thanhhv317/\"\u003elinkedin.com/in/thanhhv317\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e📅 DOB: 11/08/1998\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch3 id=\"-skills\"\u003e🛠 Skills\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eLanguages \u0026amp; Frameworks\u003c/strong\u003e: Node.js (NestJS, Express), Go, TypeScript, JavaScript, REST API, GraphQL, gRPC\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eArchitecture\u003c/strong\u003e: Microservices, Message Queue, Clean Architecture, WebSocket\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDatabases\u003c/strong\u003e: PostgreSQL, MongoDB, Meilisearch, Redis\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eBlockchain\u003c/strong\u003e: Web3.js, ethers, On-chain Data\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDevOps \u0026amp; Tools\u003c/strong\u003e: Docker, AWS (EC2, S3, Lambda, SQS), Linux, GitHub Actions (CI/CD)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTesting \u0026amp; Monitoring\u003c/strong\u003e: Jest, Prometheus, Grafana, Jaeger, Tracing\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFrontend\u003c/strong\u003e: React.js, HTML, CSS, Bootstrap\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMethodologies\u003c/strong\u003e: Agile/Scrum\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSoft Skills\u003c/strong\u003e: Problem solving, Teamwork \u0026amp; Collaboration, Planning \u0026amp; Task Management\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLanguages\u003c/strong\u003e: English\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch3 id=\"-experience\"\u003e💼 Experience\u003c/h3\u003e\n\u003ch4 id=\"cloudverse-052025---082025--senior-backend-engineer-contractor\"\u003eCloudverse (05/2025 - 08/2025) — Senior Backend Engineer (Contractor)\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003eProject: Cloud Provider\u003c/strong\u003e — Management platform for partner list using FinOps system\u003c/p\u003e","title":"Curriculum Vitae"},{"content":" 🎯 Goal: Ensure the system is stable, scalable, and production-ready before launching.\n🧱 I. CODE \u0026amp; FUNCTIONAL Code reviewed and approved by at least one senior developer Unit test coverage ≥ 80% Edge cases handled properly No N+1 queries (GraphQL/ORM optimized) No leftover console.log or debugger in code No secrets or tokens hardcoded 🚦 II. CI/CD \u0026amp; DEPLOYMENT CI pipeline set up (build → test → deploy) Rollback plan in place (script or quick revert strategy) Staging/UAT environment available and tested .env variables configured correctly (not copied from local) Proper branch/tag naming (e.g. release/v1.0.0) 🔒 III. SECURITY Auth applied on all sensitive routes (JWT, OAuth, API keys) Role \u0026amp; permission system tested No publicly exposed sensitive endpoints (/admin, /debug) Checked for XSS, SQLi, path traversal vulnerabilities Rate limiting/throttling in place for public APIs Security headers enabled (helmet, CORS, etc.) 📈 IV. PERFORMANCE \u0026amp; SCALING Load tested for target RPS (e.g. ≥ 10k req/s) Concurrent users simulated (e.g. 1k logins) DB indexed properly (EXPLAIN ANALYZE used) Redis, CDN, or in-memory caching applied File/media offloaded to external storage (e.g. S3) API only returns necessary data (REST/GraphQL select) 🧠 V. MONITORING \u0026amp; ALERTING Logging integrated (Winston, Pino, ELK, Datadog, etc.) Logs include traceId, userId, route context Metrics collection: Prometheus / Grafana / OpenTelemetry Alert configured for: High error rate (5xx) CPU \u0026gt; 80% Memory full Queue backlog increasing ⚙️ VI. INFRASTRUCTURE Load balancer configured and stable Auto-restart and healthcheck ready (PM2, Docker, k8s readiness) Database backup and restore tested Horizontal scaling/pod autoscaling set up if using k8s .env.production encrypted or managed via Vault 📋 VII. OTHER Changelog written (CHANGELOG.md) Release announcement sent to relevant teams Post-deploy checklist created (Smoke test UI/API) QA checklist completed (login, checkout, error, etc.) Graceful fallback UI for error handling /status, /health, /metrics, /version endpoints ready ✅ READY TO GO LIVE? Goal Ready? Code clean and stable ✅ Load test passed ✅ Monitoring in place ✅ Rollback plan confirmed ✅ Stakeholders notified ✅ 🔁 POST GO-LIVE ACTIONS Real-time system monitoring active User feedback monitored Latency/error rate observed 24h go-live report or postmortem (if needed) ","permalink":"https://thanhhv.github.io/wiki/go-live-checklist/","summary":"\u003cblockquote\u003e\n\u003cp\u003e🎯 \u003cstrong\u003eGoal:\u003c/strong\u003e Ensure the system is stable, scalable, and production-ready before launching.\u003c/p\u003e\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2 id=\"-i-code--functional\"\u003e🧱 I. CODE \u0026amp; FUNCTIONAL\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Code reviewed and approved by at least one senior developer\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Unit test coverage ≥ 80%\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Edge cases handled properly\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e No N+1 queries (GraphQL/ORM optimized)\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e No leftover \u003ccode\u003econsole.log\u003c/code\u003e or \u003ccode\u003edebugger\u003c/code\u003e in code\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e No secrets or tokens hardcoded\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"-ii-cicd--deployment\"\u003e🚦 II. CI/CD \u0026amp; DEPLOYMENT\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e CI pipeline set up (build → test → deploy)\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Rollback plan in place (script or quick revert strategy)\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Staging/UAT environment available and tested\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e \u003ccode\u003e.env\u003c/code\u003e variables configured correctly (not copied from local)\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Proper branch/tag naming (e.g. \u003ccode\u003erelease/v1.0.0\u003c/code\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"-iii-security\"\u003e🔒 III. SECURITY\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Auth applied on all sensitive routes (JWT, OAuth, API keys)\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Role \u0026amp; permission system tested\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e No publicly exposed sensitive endpoints (\u003ccode\u003e/admin\u003c/code\u003e, \u003ccode\u003e/debug\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Checked for XSS, SQLi, path traversal vulnerabilities\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Rate limiting/throttling in place for public APIs\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Security headers enabled (\u003ccode\u003ehelmet\u003c/code\u003e, CORS, etc.)\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"-iv-performance--scaling\"\u003e📈 IV. PERFORMANCE \u0026amp; SCALING\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Load tested for target RPS (e.g. ≥ 10k req/s)\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Concurrent users simulated (e.g. 1k logins)\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e DB indexed properly (\u003ccode\u003eEXPLAIN ANALYZE\u003c/code\u003e used)\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Redis, CDN, or in-memory caching applied\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e File/media offloaded to external storage (e.g. S3)\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e API only returns necessary data (REST/GraphQL select)\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"-v-monitoring--alerting\"\u003e🧠 V. MONITORING \u0026amp; ALERTING\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Logging integrated (Winston, Pino, ELK, Datadog, etc.)\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Logs include traceId, userId, route context\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Metrics collection: Prometheus / Grafana / OpenTelemetry\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Alert configured for:\n\u003cul\u003e\n\u003cli\u003eHigh error rate (5xx)\u003c/li\u003e\n\u003cli\u003eCPU \u0026gt; 80%\u003c/li\u003e\n\u003cli\u003eMemory full\u003c/li\u003e\n\u003cli\u003eQueue backlog increasing\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"-vi-infrastructure\"\u003e⚙️ VI. INFRASTRUCTURE\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Load balancer configured and stable\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Auto-restart and healthcheck ready (PM2, Docker, k8s readiness)\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Database backup and restore tested\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Horizontal scaling/pod autoscaling set up if using k8s\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e \u003ccode\u003e.env.production\u003c/code\u003e encrypted or managed via Vault\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"-vii-other\"\u003e📋 VII. OTHER\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Changelog written (\u003ccode\u003eCHANGELOG.md\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Release announcement sent to relevant teams\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Post-deploy checklist created (Smoke test UI/API)\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e QA checklist completed (login, checkout, error, etc.)\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Graceful fallback UI for error handling\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e \u003ccode\u003e/status\u003c/code\u003e, \u003ccode\u003e/health\u003c/code\u003e, \u003ccode\u003e/metrics\u003c/code\u003e, \u003ccode\u003e/version\u003c/code\u003e endpoints ready\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"-ready-to-go-live\"\u003e✅ READY TO GO LIVE?\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eGoal\u003c/th\u003e\n          \u003cth\u003eReady?\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eCode clean and stable\u003c/td\u003e\n          \u003ctd\u003e✅\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eLoad test passed\u003c/td\u003e\n          \u003ctd\u003e✅\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eMonitoring in place\u003c/td\u003e\n          \u003ctd\u003e✅\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eRollback plan confirmed\u003c/td\u003e\n          \u003ctd\u003e✅\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eStakeholders notified\u003c/td\u003e\n          \u003ctd\u003e✅\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003chr\u003e\n\u003ch2 id=\"-post-go-live-actions\"\u003e🔁 POST GO-LIVE ACTIONS\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Real-time system monitoring active\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e User feedback monitored\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e Latency/error rate observed\u003c/li\u003e\n\u003cli\u003e\u003cinput disabled=\"\" type=\"checkbox\"\u003e 24h go-live report or postmortem (if needed)\u003c/li\u003e\n\u003c/ul\u003e","title":"Go-live load test \u0026 deployment checklist"},{"content":"Reading is not only for fun, but also to develop clear thinking and deeper perspective.\nHere\u0026rsquo;s a list of non-technical books that can help backend engineers grow in mindset and soft skills.\n📘 Psychology \u0026amp; Thinking Thinking, Fast and Slow - Daniel Kahneman The One Thing - Gary W. Keller, Jay Papasan 🌍 Philosophy \u0026amp; Life Naval Ravikant: Để thịnh vượng và hạnh phúc - Eric Jorgenson \u0026hellip; will be updated more\n","permalink":"https://thanhhv.github.io/wiki/non-tech-books-worth-reading/","summary":"\u003cp\u003eReading is not only for fun, but also to develop clear thinking and deeper perspective.\u003cbr\u003e\nHere\u0026rsquo;s a list of non-technical books that can help backend engineers grow in mindset and soft skills.\u003c/p\u003e\n\u003ch2 id=\"-psychology--thinking\"\u003e📘 Psychology \u0026amp; Thinking\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003eThinking, Fast and Slow\u003c/em\u003e - Daniel Kahneman\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eThe One Thing\u003c/em\u003e - Gary W. Keller, Jay Papasan\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"-philosophy--life\"\u003e🌍 Philosophy \u0026amp; Life\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003eNaval Ravikant: Để thịnh vượng và hạnh phúc\u003c/em\u003e - Eric Jorgenson\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u0026hellip; will be updated more\u003c/p\u003e","title":"Non-Tech Books Worth Reading"}]